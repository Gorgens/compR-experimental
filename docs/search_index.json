[["index.html", "Computação em R: estatística experimental Cap. 1 Sobre o livro", " Computação em R: estatística experimental Eric Bastos Gorgens &amp; Marcio Leles Romarco de Oliveira 2021-01-23 Cap. 1 Sobre o livro Bem-vindo ao mundo do R. O R não é só um software, nem se resume a uma linguagem. O R é um estilo de pesquisar, estudar e ensinar. Através de seus códigos e scripts você entrará num mundo sem limites, aberto à experimentação e à troca de experiência. Um mundo em que não existe apenas uma forma de se chegar à resposta correta, mas sim uma gama de alternativas! Você deve estar se perguntando: porque começar a trabalhar com o R? A resposta passa por algumas perspectivas interessantes. R é gratuito. Por se tratar de um projeto de código aberto, você pode usar o R sem nenhum custo adicional: ou seja sem necessidade de pagar por inscrições, assinaturas, licenças ou limitações. Sendo o R aberto, você pode ter acesso ao código e ajustá-lo às suas necessidades (para mais detalhes veja: GNU General Public License version 2). Centenas de experts ao redor do mundo fazem exatamente isto e suas contribuições beneficiam milhares de usuários do R. R é uma linguagem. No R, você realiza uma análise escrevendo funções e scripts; e não clicando em botões na tela. Isto pode assustar e parecer difícil, mas na verdade, a linguagem R é uma linguagem simples de aprender e muito natural para análise de dados. Aprender uma linguagem tem vários benefícios. Por se tratar de uma linguagem interativa, o R promove uma oportunidade de experimentar e explorar os dados de forma profunda e detalhada. Um script documenta passo a passo da análise, do acesso aos dados até os resultados das análises, podendo ser executados a qualquer momento, por qualquer pessoa. Gráficos e visualização de dados. Faz parte das premissas de criações do R, a certeza de que a visualização dos dados através de gráficos é uma parte essencial de qualquer análise dos dados. Como resultado, o R oferece excelentes ferramentas para criação de gráficos, de barras até multi-painéis. Os recursos gráficos do R é influenciado pelos principais pensadores da área de visualização de dados como Bill Cleveland e Edward Tufte. Gráficos do R podem ser vistos em respeitadas publicações mundiais como The New York Times, The Economist, e o blog FlowingData. Pacote flexível de análises estatísticas. Você irá encontrar no R um conjunto de ferramentas prontamente disponíveis, desde o acesso à vários tipos de dados, até recursos para manipulação de dados, passando pelos modelos estatísticos tradicionais e modernos. Todos os recursos estão disponíveis numa plataforma orientada a objeto que torna fácil a programação e construção de relatórios. Acesso às poderosas e avançadas técnicas estatísticas. Os principais acadêmicos e pesquisadores do mundo utilizam o R para desenvolver as novidades nas áreas de estatística, máquinas de aprendizado e modelagem. Você pode encontrar extensões para o R contendo desenvolvimento de ponta na área econômica, genética e muitos outros campos. Atualmente são mais de 2000 pacotes que incrementam o seu R disponíveis para download. Uma brilhante e vibrante comunidade. Com centenas de contribuidores e mais de dois milhões de usuários ao redor do mundo, se você tiver uma dúvida sobre o R, as chances de alguém já ter esbarrada com este problema é muito grande. A comunidade é gigante e participativa. A mediana de tempo que uma pergunta leva para ser respondida no StackOverflow (maior comunidade de programadores do mundo) é de 0.0147 dias, o que equivale a 21 minutos. O R é multiplataforma rodando em Linux, Mac ou Windows. Ainda é possível configurar para rodar diretamente da nuvem. O R valoriza o que a empresa tem de mais valioso: você! Possibilidades infinitas. Com o R você não está limitado por uma sequência pré-definida de rotinas. Você pode usar todo o portfólio de códigos e soluções disponíveis na comunidade ou mesmo criar suas próprias funções. É possível inclusive combinar o R com outros recursos como uma base de dados MySQL, ou um Apache web-server, ou ainda com o Google Maps API. Qual a sua ideia? "],["delineamentos-experimentais.html", "Cap. 2 Delineamentos experimentais 2.1 ANOVA 2.2 Tipos de ANOVA", " Cap. 2 Delineamentos experimentais Delineamento experimental define a organização das unidades experimentais, em função da pergunta científica que se deseja responder. Com base no delineamento escolhido, regras precisam ser seguidas, especialmente relacionados à maneira que os tratamentos são distribuídos nas unidades experimentais. A unidade experimental é o material experimental que identifica um sistema de interesse numa pesquisa experimental e representa uma unidade da população. É sobre a unidade experimental que os tratamento serão aplicados e avaliados. Os tratamentos são variáveis manipuladas e controladas pelo analista. Desta forma, qualquer outra influência tem que ocorrer ao acaso, e por isto, as unidades experimentais devem ser o mais homogêneas possível e o tratamento deve ser a ela atribuída de forma aleatória. Outro ponto importante num delineamento experimental, é o número de repetições. Desta forma, deve possuir unidades experimentais suficientes para que os tratamentos sejam aplicados e repetidos. Quando maior o número de repetições, menor o intervalo de confiança e, portanto, mais precisa as inferências estatísticas. Existem metodologias específicas para a determinação do número ideal de repetições, mas na prática, adota-se trabalhos anteriores como referência, ou mesmo a disponibilidade de material acaba definindo o número de repetições. 2.1 ANOVA A Análise de Variância, ou simplesmente ANOVA, é uma análise estatística para determinar a contribuição de diferentes fatores na variância total de um experimento. O método foi desenvolvido em 1925 por Ronald Fisher para experimentos balanceados, ou seja, experimentos com o mesmo número de repetições em cada tratamento. No entanto, correções foram desenvolvidas para também tratar experimentos desbalanceados, como veremos mais adiante. Assim, podemos definir Análise de Variância (ANOVA) como uma técnica que decompõe a variância total e seus graus de liberdade em partes atribuídas a fatores controlados (tratamento) e a uma outra parte associada a uma causa não controlada, também chamada de resíduo. 2.1.1 Partição da variação Suponha que estamos analisando o efeito de três materiais genéticos através de um experimento inteiramente casualizado. Cada tratamento foi formado por seis repetições (parcela), cada uma contendo 36 plantas, tratando-se assim de um experimento balanceado. Resumindo: 3 tratamentos (i variando de 1 a 3) 6 repetições por tratamento (j variando de 1 a 6) 18 unidades experimentais presentes no experimento A média de altura em metros de cada uma das repetições por tratamento é: Table 2.1: Dados de exemplo. Repeticao MatGen1 MatGen2 MatGen3 Rep 1 21 19 18 Rep 2 20 19 18 Rep 3 20 17 15 Rep 4 17 13 13 Rep 5 18 16 13 Rep 6 17 14 13 ## Warning in read.table(file = file, header = header, sep = sep, quote = quote, : ## incomplete final line found by readTableHeader on &#39;./data/anova_sumRep.csv&#39; Table 2.2: Média e soma de cada tratamento. Estatistica MatGen1 MatGen2 MatGen3 Soma ? ? ? Media ? ? ? ## Warning in read.table(file = file, header = header, sep = sep, quote = quote, : ## incomplete final line found by readTableHeader on &#39;./data/anova_sumTotal.csv&#39; Table 2.3: Média e soma total. Estatistica Valor Total geral ? Media Geral ? Vamos utilizar o R para calcular as somas - sum() e médias - mean() que faltam nas tabelas acimas. Desta forma, aproveitamos para relembrar um pouco da sintaxe, bem como dos operadores matemáticos: # Cria os vetores correspondentes a cada tratamentos com suas respectivas repetições matGen1 = c(21, 20, 20, 17, 18, 17) matGen2 = c(19, 19, 17, 13, 16, 14) matGen3 = c(18, 18, 15, 13, 13, 13) # Soma das repetições do tratamento 1 s1 = sum(matGen1) print (paste(&quot;Soma MATGEN1 = &quot;, s1, sep = &quot; &quot;)) ## [1] &quot;Soma MATGEN1 = 113&quot; # Média das repetições do tratamento 1 m1 = mean(matGen1) print (paste(&quot;Media MATGEN1 = &quot;, m1, sep = &quot; &quot;)) ## [1] &quot;Media MATGEN1 = 18.8333333333333&quot; # Soma das repetições do tratamento 2 s2 = sum(matGen2) print (paste(&quot;Soma MATGEN2 = &quot;, s2, sep = &quot; &quot;)) ## [1] &quot;Soma MATGEN2 = 98&quot; # Média das repetições do tratamento 2 m2 = mean(matGen2) print (paste(&quot;Media MATGEN1 = &quot;, m2, sep = &quot; &quot;)) ## [1] &quot;Media MATGEN1 = 16.3333333333333&quot; # Soma das repetições do tratamento 3 s3 = sum(matGen3) print (paste(&quot;Soma MATGEN3 = &quot;, s3, sep = &quot; &quot;)) ## [1] &quot;Soma MATGEN3 = 90&quot; # Média das repetições do tratamento 3 m3 = mean(matGen3) print (paste(&quot;Media MATGEN3 = &quot;, m3, sep = &quot; &quot;)) ## [1] &quot;Media MATGEN3 = 15&quot; # Soma de todas as repetições, dos três tratamentos somaTotal = sum(c(matGen1, matGen2, matGen3)) print (paste(&quot;Soma total = &quot;, somaTotal, sep = &quot; &quot;)) ## [1] &quot;Soma total = 301&quot; # Média de todos os tratamentos e repetições mediaGeral = mean(c(matGen1, matGen2, matGen3)) print (paste(&quot;Media geral = &quot;, mediaGeral, sep = &quot; &quot;)) ## [1] &quot;Media geral = 16.7222222222222&quot; A partir dos resultado apresentados pelo R, nossa tabela fica assim: ## Warning in read.table(file = file, header = header, sep = sep, quote = quote, : ## incomplete final line found by readTableHeader on &#39;./data/anova_sumRep2.csv&#39; Table 2.4: Média e soma de cada tratamento calculado. Estatistica MatGen1 MatGen2 MatGen3 Soma 113.00 98.00 90 Media 18.83 16.33 15 ## Warning in read.table(file = file, header = header, sep = sep, quote = quote, : ## incomplete final line found by readTableHeader on &#39;./data/anova_sumTotal2.csv&#39; Table 2.5: Média e soma total calculado. Estatistica Valor Total geral 301.00 Media Geral 16.72 2.1.1.1 Soma de quadrados total O próximo passo será analisar a diferença de cada uma das 18 observações (3 tratamentos * 6 repetições cada) em relação à média geral: \\[desvio = x_{ij} - \\bar{x}\\] em que j indica a repetição variando de 1 a 6 e i indica o tratamento variando de 1 a 3. No R, esta operação fica fácil, pois é possível fazer de uma única vez a subtração dos elementos de um vetor pela média geral: desvio1 = matGen1 - mediaGeral desvio1 ## [1] 4.2777778 3.2777778 3.2777778 0.2777778 1.2777778 0.2777778 desvio2 = matGen2 - mediaGeral desvio2 ## [1] 2.2777778 2.2777778 0.2777778 -3.7222222 -0.7222222 -2.7222222 desvio3 = matGen3 - mediaGeral desvio3 ## [1] 1.277778 1.277778 -1.722222 -3.722222 -3.722222 -3.722222 Tabulando os desvios que calculamos acima, teríamos uma tabela da seguinte forma: Table 2.6: Desvio da observação para e média geral. MatGen1 MatGen2 MatGen3 4.28 2.28 1.28 3.28 2.28 1.28 3.28 0.28 1.72 0.28 -3.72 -3.72 1.28 -0.72 -3.72 0.28 -2.72 -3.72 Se elevarmos cada um dos desvios ao quadrado e somá-los, obtemos a soma de quadrados total (SQTotal). Esta soma de quadrados é a variação total dos dados sem levar em conta os tratamentos. \\[SQTotal = \\sum (x_{ij} - \\bar{x})^2\\] em que i indica a repetição variando de 1 a 6 e j indica o tratamento variando de 1 a 3. No R podemos calcular a soma de quadrados total como: sqTotal = sum(desvio1^2, desvio2^2, desvio3^2) print(sqTotal) ## [1] 121.6111 2.1.1.2 Soma de quadrados dos tratamentos A soma de quadrados dos tratamentos, ou a soma de quadrados entre os tratamentos, pode ser calculado pela diferença entre a média de cada tratamento em relação à média geral. \\[desvio_{i} = \\bar{x}_{i} - \\bar{x}\\] em que j indica a repetição variando de 1 a 6 e i indica o tratamento variando de 1 a 3. Para isto, o valor de cada repetição é substituído pela média do seu tratamento. Isto é, através da fórmula rep, cria-se um vetor com a média do material genético repetida 6 vezes. Neste caso estamos eliminando o efeito do erro, já que cada tratamento será representado j vezes pelo valor da sua média. Finalmente, cada repetição é subtraída pela média geral. desvioTrat1 = rep(mean(matGen1), 6) - mediaGeral desvioTrat1 ## [1] 2.111111 2.111111 2.111111 2.111111 2.111111 2.111111 desvioTrat2 = rep(mean(matGen2), 6) - mediaGeral desvioTrat2 ## [1] -0.3888889 -0.3888889 -0.3888889 -0.3888889 -0.3888889 -0.3888889 desvioTrat3 = rep(mean(matGen3), 6) - mediaGeral desvioTrat3 ## [1] -1.722222 -1.722222 -1.722222 -1.722222 -1.722222 -1.722222 Trazendo os resultados do R para uma tabela de desvios temos: Table 2.7: Desvio entre a média do tratamento e média geral. MatGen1 MatGen2 MatGen3 2.11 -0.39 -1.72 2.11 -0.39 -1.72 2.11 -0.39 -1.72 2.11 -0.39 -1.72 2.11 -0.39 -1.72 2.11 -0.39 -1.72 Os desvios são então elevados ao quadrado e somados, resultando na soma de quadrados dos tratamentos (SQTrat): sqTrat = sum(desvioTrat1^2, desvioTrat2^2, desvioTrat3^2) print(sqTrat) ## [1] 45.44444 2.1.1.3 Soma de quadrados dos resíduos A soma de quadrados dos resíduos (SQRes) pode ser denominada também como soma de quadrados dentro do tratamento. Primeiro, calculamos o desvio entre a cada uma das repetições e a média do respectivo tratamento: \\[desvio = x_{ij} - \\bar{x}_{i}\\] No R, podemos calcular da seguinte forma: desvioRes1 = matGen1 - mean(matGen1) desvioRes1 ## [1] 2.1666667 1.1666667 1.1666667 -1.8333333 -0.8333333 -1.8333333 desvioRes2 = matGen2 - mean(matGen2) desvioRes2 ## [1] 2.6666667 2.6666667 0.6666667 -3.3333333 -0.3333333 -2.3333333 desvioRes3 = matGen3 - mean(matGen3) desvioRes3 ## [1] 3 3 0 -2 -2 -2 Trazendo os resultados do R para uma tabela de desvios temos: Table 2.8: Desvio da observação para e média do tratamento MatGen1 MatGen2 MatGen3 2.17 2.67 3 1.17 2.67 3 1.17 0.67 0 -1.83 -3.33 -2 0.83 0.33 -2 -1.83 -2.33 -2 Elevando cada desvio ao quadrado e somando-os, calculamos a soma de quadrados dos resíduos: sqRes = sum(desvioRes1^2, desvioRes2^2, desvioRes3^2) print(sqRes) ## [1] 76.16667 2.1.1.4 Quadrado médio O próximo passo é montar o quadro da ANOVA e determinar os quadrados médios: ## Warning in read.table(file = file, header = header, sep = sep, quote = quote, : ## incomplete final line found by readTableHeader on &#39;./data/anova_qm.csv&#39; Table 2.9: Fórmulas para o caluclo do quandrado médio. Fonte.de.variacao Soma.de.quadrados Graus.de.liberdade Quadrado.medio Trat SQTrat \\(i-1\\) \\(SQTotal / (i-1)\\) Residuos SQRes \\(i * (j - 1)\\) \\(SQRes / (i * (j-1))\\) Total SQTotal \\((i * j) - 1\\) Tanto a soma de quadrados, como os graus de liberdade são aditivos, isto é, obtendo dois termos do quadro de variância, o terceiro pode ser derivado. Na prática, calcula-se a soma de quadrados total e a soma de quadrados do tratamento. Por diferença, obtém-se a soma de quadrados dos resíduos. O mesmo raciocínio vale para os graus de liberdade. O quadrado médio, nada mais é que uma variância. Por isso, divide-se a soma de quadrados pelos graus de liberdade. Os quadrados médios são calculados da seguinte forma: qmTrat = sqTrat / (3 - 1) print(qmTrat) ## [1] 22.72222 qmRes = sqRes / (3 * (6 - 1)) print(qmRes) ## [1] 5.077778 2.1.1.5 Teste F Assim, o objetivo final da ANOVA é comparar a variância dos tratamentos relativa à variância dos resíduos. O valor da razão entre estas duas variâncias segue a distribuição F, recorrendo-se então à uma tabela de distribuição amostral da razão F para avaliar a significância do teste. Fcalc = qmTrat / qmRes print(Fcalc) ## [1] 4.474836 O quadro final da ANOVA será: ## Warning in read.table(file = file, header = header, sep = sep, quote = quote, : ## incomplete final line found by readTableHeader on &#39;./data/anova_final.csv&#39; Table 2.10: Quandro final da ANOVA Fonte.de.variaÃ.Ã.o Soma.de.quadrados Graus.de.liberdade Quadrado.mÃ.dio FCalc Trat 45.44 2 22.72 4.47 ResÃ­duos 76.17 15 5.08 NA Total 121.61 17 NA NA A hipótese nula é de que as variâncias dos tratamentos é igual à variância populacional, ou variância dos resíduos. Um teste não significativo aceita-se a hipótese nula. Já um teste significativo rejeita-se a hipótese nula. Ftabelado = qf(0.95, 2, 15) print(Ftabelado) ## [1] 3.68232 No nosso exercício, o Fcalc &gt; Ftabelado, assim o teste F é significativo e a hipótese nula é rejeitada para um nível de significância de 95%. A variância dos tratamentos não pode ser considerada igual à variância da população. Na prática isto indica que existe um efeito significativo dos tratamentos. Se o teste F é não significativo (F calculado &lt; F tabelado), entende-se que os tratamentos não influenciaram as observações e a análise de seu experimento encerra-se aqui. Por outro lado, o teste F significativo indica que pelo menos um dos tratamentos influenciou os dados observados. Se apenas dois tratamentos tiverem sido realizados, o teste F é conclusivo e as médias dos tratamentos podem ser comparadas diretamente. Se três ou mais tratamentos estiverem sendo comparados, o teste F é inconclusivo, uma vez que diz apenas que existe uma influência dos tratamentos, sem no entanto indicar qual deles é melhor ou pior. Assim uma pergunta surge: como os tratamentos se diferem uns dos outros? Entram em cena os testes de médias ou a análise de regressão. Sendo os tratamentos qualitativos e significativos, o teste de médias irá dizer quais tratamentos são iguais e quais tratamentos são diferentes. Sendo os tratamentos quantitativos e significativos, utiliza-se a análise de regressão para definir o ponto ótimo. Para facilitar, vamos resumir o que vimos até agora numa árvore de decisão: Fluxograma de decisão para interpretação de uma ANOVA 2.2 Tipos de ANOVA Existem pelo menos 3 formas para se calcular a soma de quadrados da ANOVA, que são conhecidos como soma de quadrados do TIPO I, TIPO II e TIPO III. Esta notação foi introduzida pelo software SAS, mas acabou sendo adotada pela comunidade para diferenciar entre as diferentes formas de se calcular a soma de quadrados para composição da ANOVA. A recomendação de uso dos diferentes tipos de soma de quadrados leva a calorosas discussões entre estatísticos. De modo geral, o tipo I é indicado para dados balanceados. O tipo II e tipo III são mais indicados para dados desbalanceados. No caso de experimentos balanceados, os três tipos de ANOVA apresentam resultados idênticos. Variações no cálculo da soma de quadrados Vamos partir de um modelo que considere dois fatores A e B; sendo portanto dois fatores principais e a interação AB. O modelo completo pode ser então representado por SQ(A, B, AB). Também podem ser considerados modelos parciais como SQ(A, B) que indica um modelo sem interação, SQ(B, AB) um modelo que não considera efeitos do fator A e assim por diante. A influência de um determinado fator (ou interação) pode ser testada examinando as diferenças entre modelos. Por exemplo, para determinar a presença de interação entre os fatores, um teste F é conduzido comparando o modelo com interação SQ(A, B, AB) e o modelo sem interação SQ(A, B). 2.2.1 ANOVA Tipo I A ANOVA tipo I testa primeiro o efeito de A, seguido do efeito de B dado que se conhece A, seguido pela interação dado que os efeitos principais já são conhecidos. Esta ordem é a razão desta ANOVA ser conhecida como soma de quadrados sequencial. SQ(A) para o fator A. SQ(B | A) para fator B. SQ(AB | B, A) para interação AB. 2.2.2 ANOVA Tipo II Este tipo de ANOVA testa o efeito de um dos fatores principais dado que o outro já é conhecido. Assim, assume-se a não significância da interação. Sugere-se então que se teste primeiro SQ(AB | A, B). Se de fato a interação for não significativa, então o tipo II é estatisticamente mais poderoso que o tipo III. Computacionalmente, a ANOVA do tipo II é equivalente à ANOVA tipo I, alterando a ordem dos fatores e selecionando as saídas corretas. SQ(A | B) para o fator A. SQ(B | A) para o fator B. 2.2.3 ANOVA Tipo III Este tipo de ANOVA só é válido quando a interação é significativa. No entanto, em muitos casos não se tem interesse em analisar os fatores principais quando a interação está presente, ou seja, na presença de interação, os efeitos principais deixam de ser interessantes isoladamente). SQ(A | B, AB) para o fator A. SQ(B | A, AB) para o fator B. Assim, na prática, só é necessário preocupar com dados desbalanceados quando a interação entre fontes de variação for considerada no modelo estatístico do experimento. Ao longo dos capítulos, veremos caso a caso, quando a interação deve ou não deve ser considerada. "],["pressuposições-e-transformações.html", "Cap. 3 Pressuposições e transformações 3.1 Logarítmica 3.2 Raiz quadrada 3.3 Arcoseno", " Cap. 3 Pressuposições e transformações Duas são as pressuposições da ANOVA: Homogeneidade de variâncias Normalidade dos resíduos Neste momento, não vamos nos preocupar com os testes estatísticos utilizados para a verificação das pressuposições. Até mesmo, porque as pressuposições precisam ser analisadas após a análise de variância ser realizada, já que a normalidade da variável não garante a normalidade dos resíduos. No caso de uma das pressuposições não serem atendidas, os dados devem ser transformados, a análise refeita e as pressuposições novamente verificadas. Na sequência vamos conhecer as principais transformações na área das ciências florestais e biológicas. 3.1 Logarítmica Esta transformação é indicada para variáveis contínuas e consiste em obter o log de cada uma das observações. É possível usar tanto o log base-10 quanto o log base-e. Utilizar um ou outro não faz nenhuma diferença para o teste estatístico, pois a única diferença é a constante logarítmica: a base-10 ou a base-e. Não deixe de registrar qual a base você utilizou já que esta decisão influencia a interpretação do coeficiente angular e o coeficiente de inclinação da regressão num eventual desdobramento. a = 5.7 trans_a = log(a) Para reverter a transformação realizada acima no R: exp(trans_a) ## [1] 5.7 Lembre-se de que se seus dados possuem zeros ou valores negativos você não pode usar a transformação logarítmica. Uma saída é adicionar uma constante a cada número para torná-lo positivo e não zero. Se o seus dados forem contagem com presença de zero, a solução é adicionar 0,5 a cada observação. Muitas variáveis biológicas tem distribuição log-normal, isto mostra que após a transformação logarítmica, os valores passam a ter distribuição normal. Isto se deve ao fato de que se você pega um conjunto de fatores independentes e os multiplica, o produto é log-normal. Por exemplo, a altura de uma árvore é uma função de (nitrogênio x água x luz x pragas). Matematicamente esta função é uma log-normal. 3.2 Raiz quadrada Esta transformação consiste na obtenção da raiz quadrada de cada uma das observações. Esta transformação é muito utilizada para variáveis de contagem. No entanto ela só pode ser utilizada para dados positivos. Em caso de número negativos, uma saída é adicionar uma constante a todas as observações eliminando assim as observações negativas. b = 10 trans_b = sqrt(b) Para reverter a transformação: trans_b^2 ## [1] 10 3.3 Arcoseno Esta transformação consiste em calcular o arcoseno da raiz quadrada de cada uma das observações. O resultado é dado em radianos e não em graus, e pode variar de -/2 a /2. Os números para serem transformados pelo arcoseno precisam estar entre -1 e 1. Por isso, é comum utilizar esta transformação para proporções, cuja amplitude geralmente está entre 0 e 1. Embora recomendado na literatura, tenha cuidado ao utilizar esta transformação, especialmente quando você não tiver certeza se sua variável é categórica (binária) ou contínua. c = 0.8 trans_c = asin(sqrt(c)) Para reverter a transformação: (sin(trans_c))^2 ## [1] 0.8 "],["anova-no-r.html", "Cap. 4 ANOVA no R 4.1 Pacote ExpDes.pt 4.2 Pacote easyanova", " Cap. 4 ANOVA no R A boa notícia é que o R conta com diversos pacotes desenvolvidos que realizam toda a sequência de análise, tanto para o caso balanceado, quanto para o caso desbalanceado. Ao longo deste livro usaremos dois pacotes: ExpDes.pt easyanova Os pacotes no R são desenvolvidos e disponibilizados de forma oficial no repositório do R, chamado de CRAN. Embora um pacote precise seguir determinadas regras mínimas para ser disponibilizado no repositório oficial, o estilo de cada desenvolvedor leva a diferenças significativas nas características e no funcionamento dos pacotes. 4.1 Pacote ExpDes.pt O pacote ExpDes.pt (e sua versão em inglês ExpDes) foi desenvolvido por uma equipe da Universidade de Alfenas (Unifal) composta por Eric Batista Ferreira, Pórtya Piscitelli Cavalcanti, Denismar Alves Nogueira. Este pacote realiza a análise de diversos delineamentos experimentais e desdobramento tanto de fatores qualitativos quanto de fatores quantitativos. O pacote ExpDes.pt só realiza o teste de normalidade dos resíduos. Para instalar o ExpDes.pt: install.packages(&quot;ExpDes.pt&quot;) O pacote ExpDes.pt ao ser instalado trás diversas funções para analisar os seguintes delineamentos experimentais: DIC: delineamento inteiramente casualizado DBC: delineamento em blocos casualizados DQL: delineamento em quadrado latino Experimentos em esquema de fatorial duplo (em DIC e DBC) Experimentos em esquema de parcelas subdivididas (em DIC e DBC) Experimentos em esquema de fatorial duplo com um tratamento adicional (em DIC e DBC) Experimentos em esquema de fatorial triplo (em DIC e DBC) Experimentos em esquema de fatorial triplo com um tratamento adicional (em DIC e DBC) O pacote permite ainda o desdobramento de níveis quantitativos a partir de modelos de regressão até o terceiro grau. Ou no caso de níveis qualitativos, o desdobramento ocorre por testes de comparação múltipla por meio dos testes: Teste de Tukey Teste de Student-Newman-Keuls (SNK) Teste de Scott-Knott Teste de Duncan Teste t (LSD) Teste t de Bonferroni (LSD protegido) Teste Bootstrap Uma vez instalados, os pacotes precisam ser ativados sempre que sua utilização for necessária. A ativação pode ser feita pelo comando: require(ExpDes.pt) Uma vez ativado, as funções do pacote passam a estar disponíveis para o usuário. Para conhecer os parâmetros e o funcionamento da função, a página de ajuda pode ser consultada digitando no console ? seguido do nome da função: ?dic Toda função no R é composta por parâmetros obrigatórios e parâmetros opcionais. Esta indicação será obtido analisando a sintaxe da função, também disponível na página de ajuda. Como exemplo, consultando a página de ajuda da função dic, veremos que a sintaxe básica da funçao é: dic(trat, resp, quali = TRUE, mcomp = &quot;tukey&quot;, sigT = 0.05, sigF = 0.05) Pela sintaxe apresentada acima, dois parâmetros são obrigatórios: trat e resp. Estes parâmetros correspondem às colunas da nossa base de dados que correspondem ao tratamento e à variável resposta. Os demais parâmetros não são obrigatório pois já estão pré-definidos. Por exemplo, o parâmetro quali está pré-definido como TRUE. Isto implica que os níveis do tratamento serão interpretados como qualitativos. Assim, se o experimento possuir tratamento com níveis quantitativos, como por exemplo dosagem de nutrientes, o parâmetro quali deverá ser definido como FALSE. Os demais parâmetros optativos indicam: mcomp: o teste de média que será aplicado caso seja necessário realizar o desdobramento dos tratamentos. O parâmetro vem pré-definido como Teste de Tukey (Tukey). sigT: o nível de significância para o teste de médias. Pré-definido como 5% (0,05). sigF: o nível de significância para o teste F da análise de variância. Pré-definido como 5% (0,05). Infelizmente, o pacote ExpDes.pt só é capaz de computar a ANOVA do Tipo I, e é por isto os experimentos desbalanceados não devem ser analisados por este pacote. 4.2 Pacote easyanova O pacote easyanova foi desenvolvido pelo professor Emmanuel Arnhold, que leciona disciplinas de estatística aplicada à experimentação agropecuária em nível de graduação e pós-graduação na Universidade Federal de Goiás (UFG). O pacote easyanova pode ser utilizado para qualquer tipo de experimento - balanceado e desbalanceado - já que possui um mecanismo que define o tipo de ANOVA com base na estrutura dos dados apresentados. Outra vantagem é que este pacote realiza tanto o teste de normalidade quanto o teste de homogeneidade de variâncias. Para instalar o easyanova: install.packages(&quot;easyanova&quot;) Estando o pacote instalado, a sua ativação pode ser feita através da função require(): require(easyanova) Diferentemente do pacote ExpDes.pt, o easyanova possui apenas duas funções básicas para análise de experimentos: ea1() ea2() A definição do delineamento e/ou do esquema é feito através de um parâmetro dentro destas duas funções. Assim, através da definição do parâmetro design, a função ea1() é capaz de analisar os seguintes delineamentos: inteiramente casualizado blocos casualizados quadrado latino several latin squares análise de covariância (dic) análise de covariância (dbc) blocos incompletos tipo I e II blocos incompletos tipo III ou blocos aumentados blocos incompletos tipo III em experimentos com animais lattice (intra-blocos) lattice (inter-blocos) switchback switchback em blocos teste Kruskal-Wallis teste Friedman Já a função ea2() é é capaz, através da definição do parâmetro design, de analisar os seguintes delineamentos: fatorial duplo inteiramente casualizado fatorial duplo em blocos casualizados fatorial duplo em quadrados latinos parcela subdividida inteiramente casualizado parcela subdividida em blocos casualizados parcela dividida em quadrados latinos fatorial triplo inteiramente casualizado fatorial triplo em blocos casualizados fatorial duplo em parcela subdividida (DIC) fatorial duplo em parcela subdividida (DBC) blocos hierárquicos quadrado latino com linhas hierárquicas quadrado latino com linhas e colunas hierárquicas Uma diferença importante entre os pacotes ExpDes.pt e easyanova é a forma de apresentação dos dados. No ExpDes.pt apresentamos os vetores correspondentes às fontes de variação isoladamente. Isto é, apresentamos um vetor com os tratamentos (ex: dic2\\(Tratamento), depois um vetor com a variável de interesse (ex: dic2\\)Altura). Já no pacote easyanova, as fontes de variação devem ser apresentadas em forma de dataframe contendo exatamente as fontes de variação (colunas tratamento e altura) e a repetição. Para cada um dos delineamentos suportados, o pacote easyanova apresenta uma base exemplo que pode ser identificada via página de ajuda: ?ea1 ou ?ea2. Tendo como exemplo o experimento em delineamento inteiramente casualizado seria analisado através da função ea1() cuja sintaxe básica é: ea2(data, design = 1, alpha = 0.05, list = FALSE, p.adjust=1, plot=2) O parâmetro design vem pré-definido como 1. Assim, fique atento em defini-lo de acordo com o design correto para o seu experimento. Embora pela sintaxe acima, o único parâmetro obrigatório seja a base de dados - data, fica evidente que o design também precisa ser corretamente informado, de acordo com o delineamento do experimento a ser analisado. Um outro parâmetro opcional que vale a pena ser mencionado aqui é o plot. Três opções podem ser utilizadas para este parâmetro: indicando gráfico boxplot dos resíduos. indicando gráfico de dispersão dos resíduos padronizados em função dos dados sequenciais. indicando gráfico de dispersão dos resíduos padronizados em função dos quantis teóricos. As funções ea1() e ea2() retornam uma lista contendo a análise de variância, os desdobramentos e os testes de comparações múltiplas. Veremos o conteúdo da lista durante as análises, uma vez que pode variar em função do delineamento que será sendo analisado. Lembre-se! Delineamentos balanceados serão analisados no pacote ExpDes.pt (ou sua versão com saídas em inglês ExpDes). Já os delineamentos desbalanceados serão analisados com o pacote easyanova. "],["investigando-os-dados.html", "Cap. 5 Investigando os dados 5.1 Plot: Gráfico de dispersão 5.2 Boxplot: Gráfico de caixas", " Cap. 5 Investigando os dados Nosso primeiro desejo ao receber os dados é partir para a análise estatística. Mas espere! Antes de partir para uma análise de variância e teste de média, explore seus dados através dos diferentes pacotes gráficos disponíveis no R. Neste livro ficaremos com dois tipos de gráficos disponíveis no pacote básico do R: plot boxplot Para quem busca opções avançadas para construção e gráficos recomendamos os pacotes: lattice: http://www.statmethods.net/advgraphs/trellis.html ggplot2: http://docs.ggplot2.org/current/ 5.1 Plot: Gráfico de dispersão A função plot() é indicada para analisar duas variáveis quantitativas, já que uma assumirá o eixo x e outra o eixo y, sendo ambos os eixos numéricos e contínuos. Para exemplificar o uso das funções gráficas, utilizaremos os dados de um experimento sobre o aparecimento de brotos em função do mês em que a poda é realizada. Deseja-se encontrar em qual mês que a poda deve ser realizada visando minimizar o número de brotos. exp.grafico = read.csv(&quot;./data/Exemplo para Graficos.csv&quot;, sep = &quot;,&quot;, dec = &quot;.&quot;) plot(data = exp.grafico, Brotos ~ MesPoda, xlab = &quot;Mes da poda&quot;, ylab = &quot;Numero de brotos&quot;) A interpretação de um gráfico de dispersão é bastante intuitiva e direta. Em geral, no eixo X (horizontal) coloca-se a variável que espera-se influenciar de alguma maneira a variável que está no eixo Y (vertical). Desta maneira, analisa-se o quanto a variável do eixo X está influenciando a variável do eixo Y. No exemplo apresentado acima, a nossa variável mês de poda, influencia positivamente o número de brotos. Uma vez que quanto maior o mês de poda, maior é o número de brotos. Neste caso, estamos observando uma relação diretamente proporcional. 5.2 Boxplot: Gráfico de caixas A função boxplot() é indicada para analisar uma variável categórica e outra variável contínua. Situação ideal, por exemplo, para verificar a influência de tratamentos qualitativos sobre uma variável de interesse. Ou ainda, avaliar o efeito do bloco sobre a variável de interesse. exp.grafico = read.csv(&quot;./data/Exemplo para Graficos.csv&quot;, sep = &quot;,&quot;, dec = &quot;.&quot;) boxplot(data = exp.grafico, Brotos ~ Bloco, xlab = &quot;Bloco&quot;, ylab = &quot;Numero de brotos&quot;) A interpretação do boxplot pode parecer complicada, já que este gráfico apresenta uma série de informações estatísticas em um único gráfico. Mas é justamente esta característica que torna este gráfico tão utilizado e tão importante. Existem variações do boxplot considerando diferentes estatísticas na sua construção, mas vamos ficar com a estrutura clássica formada por uma linha horizontal, dentro de uma caixa, sobreposta a uma linha vertical (do inglês whisker, também conhecida como fios do bigode). A linha horizontal no interior da caixa indica a mediana, ou o segundo quartil. Os limites da caixa indicam o primeiro e o terceiro quartil. Os fios do bigode (ou whiskers) indicam o máximo e o mínimo, excluindo outliers. No exemplo que apresentamos acima, não houve a presença de outliers. A função boxplot assume como outlier dados que estão acima ou abaixo de 1.5 vezes a distância inter-quartil. Estes pontos considerados outlier serão marcadas pontualmente no gráfico. O gráfico criado com a função boxplot() não remove os outliers, apenas exibe no gráfico. Assim, cabe a você a decisão de removê-los ou não. "],["delineamento-inteiramente-casualizado.html", "Cap. 6 Delineamento inteiramente casualizado 6.1 Recapitulando 6.2 O caso balanceado 6.3 Outro caso balanceado 6.4 O caso desbalanceado", " Cap. 6 Delineamento inteiramente casualizado Este é sem dúvida o caso mais simples dos delineamentos experimentais. Aqui, o fenômeno de estudo se resume a apenas duas fontes de variação: uma fonte de variação conhecida determinada pelo tratamento e uma fonte de variação desconhecida determinada pelo resíduo. 6.1 Recapitulando A análise começa pela determinação das somas de quadrados total, composta pela soma de quadrados do tratamento e pela soma de quadrados do resíduo. Uma vez obtidas as somas de quadrados, calculam-se os quadrados médios e o valor da estatística F. Se F calculado for superior ao F tabelado, assume-se que existe um efeito devido aos tratamentos, ao passo que se F calculado for inferior ao F tabelado, não há evidências suficientes para rejeitar a hipótese nula, aceitando-se a hipótese de que não existe efeito dos tratamentos. Sendo o efeito dos tratamentos significativo, realiza-se o desdobramento do efeito dos tratamentos através de um teste de médias se os tratamentos forem qualitativos, ou uma análise de regressão se os tratamentos forem quantitativos. 6.2 O caso balanceado Para exemplificar o caso balanceado, será analisado um estudo sobre a influência de três diferentes tipos de substrato no crescimento em altura de mudas. Cada tipo de substrato foi utilizado na germinação de 10 plantas. 90 dias após o semeio, as alturas das plântulas foram medidas e registradas numa planilha eletrônica (extensão .csv). Os dados podem ser resumidos através dos seguintes tópicos: Tratamento: 3 substratos 10 repetições Variável de interesse: altura Abaixo seguem as medições de altura tabuladas. Embora o R seja compatível com diversas extensões de planilhas eletrônicas, utilizaremos ao longo do livro arquivos em extensão .csv. Table 6.1: Dados de delineamento inteiramente casualizado tratamento rep altura Substrato 1 1 1.2 Substrato 1 2 8.6 Substrato 1 3 8.6 Substrato 1 4 3.7 Substrato 1 5 9.9 Substrato 1 6 2.5 Substrato 1 7 6.2 Substrato 1 8 6.2 Substrato 1 9 1.2 Substrato 1 10 3.7 Substrato 2 1 2.5 Substrato 2 2 8.6 Substrato 2 3 7.4 Substrato 2 4 6.2 Substrato 2 5 9.9 Substrato 2 6 2.5 Substrato 2 7 6.2 Substrato 2 8 6.2 Substrato 2 9 1.2 Substrato 2 10 3.7 Substrato 3 1 3.7 Substrato 3 2 9.9 Substrato 3 3 11.1 Substrato 3 4 7.4 Substrato 3 5 7.4 Substrato 3 6 3.7 Substrato 3 7 6.2 Substrato 3 8 8.6 Substrato 3 9 11.1 Substrato 3 10 11.1 O primeiro passo é importar o arquivo csv contendo os resultados do experimento para dentro do R. Esta tarefa pode ser realizada através do seguinte comando: dic1 = read.csv(&quot;./data/Experimento DIC 1.csv&quot;) Lembre-se que de acordo com a formatação regional do seu computador pode ser necessário informar o separador de coluna e/ou separador decimal. Veja alguns exemplos de sintaxe logo em sequência. # Para o caso de separador decimal &#39;.&#39; e deparador de coluna&#39;,&#39; dic1 = read.csv(&quot;Experimento DIC 1.csv&quot;, sep = &quot;,&quot;, dec = &quot;.&quot;) # Para o caso de separador decimal &#39;,&#39; e separador de colune &#39;;&#39; dic1 = read.csv(&quot;Experimento DIC 1.csv&quot;, sep = &quot;;&quot;, dec = &quot;,&quot;) Com a importação, cria-se um objeto chamado dic1, contendo os dados do experimento num formato de dataframe. Antes de partir para a análise, é fundamental explorar os dados de forma gráfica para conhecer melhor os dados e antecipar o resultado da análise estatística. A construção do gráfico ajuda na compreensão do fenômeno estudado e na validação da análise estatística escolhida. Por se tratar de um experimento com o tratamento formado por níveis qualitativos, recomenda-se o uso do boxplot(). boxplot(data = dic1, altura ~ tratamento) Pelo gráfico obtido, é razoável esperar que não haja diferenças significativas entre os tratamentos (3 substratos), pois existe uma grande sobreposição entre os interquartis dos substratos. Assim, espera-se que a análise estatística do experimento corrobore a conclusão empírica baseada no interpretação do gráfico. Com a função dic() do pacote ExpDes.pt será possível realizar toda a análise de um experimento de delineamento inteiramente casualizado, inclusive o desdobramento caso o teste F seja significativo e o tratamento tenha três ou mais níveis. Lembre-se que O pacote ExpDes.pt não faz parte da instalação padrão do R, e precisa ser adicionado à parte. A sintaxe básica da função dic() é: dic(trat, resp, quali = TRUE, mcomp = &quot;tukey&quot;, sigT = 0.05, sigF = 0.05) No nosso experimento, não será necessário alterar nenhum parâmetro opcional, sendo então nosso comando construído da seguinte maneira: require(ExpDes.pt) dic(dic1$tratamento, dic1$altura) ## ------------------------------------------------------------------------ ## Quadro da analise de variancia ## ------------------------------------------------------------------------ ## GL SQ QM Fc Pr&gt;Fc ## Tratamento 2 49.299 2 2.7908 0.079121 ## Residuo 27 238.476 3 ## Total 29 287.775 1 ## ------------------------------------------------------------------------ ## CV = 47.83 % ## ## ------------------------------------------------------------------------ ## Teste de normalidade dos residuos ## Valor-p: 0.06889791 ## De acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais. ## ------------------------------------------------------------------------ ## ## ------------------------------------------------------------------------ ## Teste de homogeneidade de variancia ## valor-p: 0.937449 ## De acordo com o teste de bartlett a 5% de significancia, as variancias podem ser consideradas homogeneas. ## ------------------------------------------------------------------------ ## ## De acordo com o teste F, as medias nao podem ser consideradas diferentes. ## ------------------------------------------------------------------------ ## Niveis Medias ## 1 Substrato 1 5.18 ## 2 Substrato 2 5.44 ## 3 Substrato 3 8.02 ## ------------------------------------------------------------------------ A primeira parte da análise é o quadro da variância que apresenta as fontes de variação com seus respectivos graus de liberdade, somas de quadrados e quadrados médio. Neste quadro também é apresentado o resultado do F calculado, que é a razão do quadrado médio do resíduo com o quadrado médio do tratamento. No capítulo sobre a análise de variância, o quadro da ANOVA terminava aqui com o F calculado, sendo seguido pela análise de uma tabela da estatística F para comparar o valor do F calculado com o valor de F tabelado. Nos softwares, não é necessário recorrer à tabela F, já que o p-valor oferece uma interpretação direta da significância. O p-valor do experimento foi 0.079121, o que equivale à um grau de significância de 7.9%. Sendo o nível de significância do nosso experimento é de 5%, o p-valor ficou acima da tolerância, indicando assim que o experimento não é significativo para um nível de 5%. Obviamente, também não é significativo para um nível de 1%. Logo abaixo do quadro da ANOVA, é apresentado o coeficiente de variação do experimento (CV): 47.83%. O CV é utilizado para medir a precisão do experimento, representado pelo o desvio-padrão expresso como porcentagem da média. A interpretação do CV é muito subjetiva e varia muito entre as áreas da ciência. Na área das ciências agrárias, convencionou-se que valores acima de 30% são considerados excessivos. Outra informação importante antes de aceitar o resultado da ANOVA, é verificar se os resíduos apresentam normalidade. Esta é uma pressuposição importante, uma vez que valida a escolha do modelo teórico do DIC para explicar o fenômeno: \\[Y = Xmed + TRAT + Erro\\] A não normalidade coloca em xeque o modelo teórico escolhido. Sendo então indicado a transformação dos dados e novo processamento da análise. A pressuposição deve então ser novamente verificada. Obtendo normalidade, os resultados obtidos com a variável transformada podem ser utilizados. Caso contrário, recomenda-se o uso de testes não paramétricos. No nosso exemplo, o teste de normalidade foi não significativo (p-valor = 0.06) e portanto não há evidências para rejeitar a hipótese de normalidade dos resíduos. A última parte da saída apresenta o resultado do desdobramento caso o teste F seja significativo. No nosso experimento, os tratamentos não são significativos e portanto, apresenta-se apenas a média de cada tratamento. 6.3 Outro caso balanceado Neste exemplo, segue um experimento em delineamento inteiramente casualizado, em que se avalia a resposta no desenvolvimento em altura das plantas de quatro níveis de um nutriente. Cada nível de nutriente foi repetido 6 vezes. Assim o experimento pode ser resumido como: Tratamento: 4 dosagens de um nutriente 6 repetições Variável de interesse: altura Table 6.2: Dados de outro delineamento inteiramente casualizado tratamento rep altura 0 1 32.3 0 2 50.6 0 3 50.6 0 4 38.8 0 5 37.1 0 6 26.3 25 1 46.3 25 2 50.3 25 3 47.5 25 4 45.6 25 5 63.9 25 6 36.3 50 1 68.5 50 2 93.9 50 3 96.5 50 4 77.7 50 5 77.7 50 6 68.8 75 1 26.3 75 2 40.3 75 3 37.7 75 4 35.1 75 5 33.9 75 6 26.3 O primeiro passo é importar o arquivo csv contendo os resultados do experimento para dentro do R. Esta tarefa pode ser realizada através do seguinte comando: dic2 = read.csv(&quot;./data/Experimento DIC 2.csv&quot;) Antes de chamar a análise estatística, recomenda-se explorar os dados graficamente. Por se tratar de um tratamento de níveis quantitativos, o gráfico de dispersão é mais adequado: plot(data = dic2, altura ~ tratamento) O gráfico indica que a dosagem de 50 apresenta um desenvolvimento em altura superior às demais dosagens. Outro ponto que fica claro com o gráfico, é que o tratamento tem um efeito quadrático sobre a altura. Por se tratar de um caso balanceado, a análise estatística pode ser realizada com a função dic() do pacote ExpDes.pt: require(ExpDes.pt) dic(dic2$tratamento, dic2$altura, quali = FALSE) ## ------------------------------------------------------------------------ ## Quadro da analise de variancia ## ------------------------------------------------------------------------ ## GL SQ QM Fc Pr&gt;Fc ## Tratamento 3 7970.8 2 29.789 1.413e-07 ## Residuo 20 1783.8 3 ## Total 23 9754.7 1 ## ------------------------------------------------------------------------ ## CV = 18.76 % ## ## ------------------------------------------------------------------------ ## Teste de normalidade dos residuos ## Valor-p: 0.1590112 ## De acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais. ## ------------------------------------------------------------------------ ## ## ------------------------------------------------------------------------ ## Teste de homogeneidade de variancia ## valor-p: 0.5117623 ## De acordo com o teste de bartlett a 5% de significancia, as variancias podem ser consideradas homogeneas. ## ------------------------------------------------------------------------ ## ## Ajuste de modelos polinomiais de regressao ## ------------------------------------------------------------------------ ## ## Modelo Linear ## ========================================= ## Estimativa Erro.padrao tc valor.p ## ----------------------------------------- ## b0 48.2233 3.2258 14.9493 0 ## b1 0.0566 0.0690 0.8206 0.4215 ## ----------------------------------------- ## ## R2 do modelo linear ## -------- ## 0.007536 ## -------- ## ## Analise de variancia do modelo linear ## =========================================================== ## GL SQ QM Fc valor.p ## ----------------------------------------------------------- ## Efeito linear 1 60.0668 60.0668 0.67 0.42152 ## Desvios de Regressao 2 7,910.7750 3,955.3870 44.35 0 ## Residuos 20 1,783.8380 89.1919 ## ----------------------------------------------------------- ## ------------------------------------------------------------------------ ## ## Modelo quadratico ## ========================================= ## Estimativa Erro.padrao tc valor.p ## ----------------------------------------- ## b0 34.1525 3.7579 9.0881 0 ## b1 1.7451 0.2414 7.2292 0 ## b2 -0.0225 0.0031 -7.2990 0 ## ----------------------------------------- ## ## R2 do modelo quadratico ## -------- ## 0.603674 ## -------- ## ## Analise de variancia do modelo quadratico ## =========================================================== ## GL SQ QM Fc valor.p ## ----------------------------------------------------------- ## Efeito linear 1 60.0668 60.0668 0.67 0.42152 ## Efeito quadratico 1 4,751.7200 4,751.7200 53.28 0 ## Desvios de Regressao 1 3,159.0540 3,159.0540 35.42 1e-05 ## Residuos 20 1,783.8380 89.1919 ## ----------------------------------------------------------- ## ------------------------------------------------------------------------ ## ## Modelo cubico ## ========================================= ## Estimativa Erro.padrao tc valor.p ## ----------------------------------------- ## b0 39.2833 3.8556 10.1888 0 ## b1 -1.4702 0.5917 -2.4846 0.0219 ## b2 0.1006 0.0209 4.8101 0.0001 ## b3 -0.0011 0.0002 -5.9514 0.00001 ## ----------------------------------------- ## ## R2 do modelo cubico ## - ## 1 ## - ## ## Analise de variancia do modelo cubico ## =========================================================== ## GL SQ QM Fc valor.p ## ----------------------------------------------------------- ## Efeito linear 1 60.0668 60.0668 0.67 0.42152 ## Efeito quadratico 1 4,751.7200 4,751.7200 53.28 0 ## Efeito cubico 1 3,159.0540 3,159.0540 35.42 1e-05 ## Desvios de Regressao 0 0 0 0 1 ## Residuos 20 1,783.8380 89.1919 ## ----------------------------------------------------------- ## ------------------------------------------------------------------------ Note que o comando utilizado é muito semelhante ao exemplo anterior, com apenas uma diferença no parâmetro quali. Neste experimento, utiliza-se o parâmetro como FALSE por se tratar de um experimento com tratamento quantitativo. O modelo estatístico pode ser aceito uma vez que não há evidências para rejeitar a hipótese de normalidade dos resíduos. Desta forma, pode-se dar sequência na interpretação dos resultados da análise do experimento. Os tratamentos podem ser considerados significativos já que seu p-valor é inferior a 1%. O desdobramento do tratamento é realizado através de um teste de regressão, já que os níveis do tratamento são quantitativos. Como padrão, a função dic() desdobra os níveis do tratamento em três modelos: linear , quadrático e cúbico. Pelo gráfico de dispersão criado na fase de exploração dos dados, espera-se que o modelo quadrático seja o mais adequado para representação dos experimento. Com base nos resultados do desdobramento, nota-se que o modelo linear e cúbico são claramente inadequados. No caso do modelo linear, o p-valor indica não significância do efeito linear, reforçado pelo coeficiente de determinação próximo a zero. O efeito cúbico, também foi inadequado pela falta de graus de liberdade. Como experimento analisado conta apenas com 4 níveis no tratamento, não sobra graus de liberdade para o resíduo. O modelo quadrático, por sua vez, apresenta um efeito significativo frente à análise de variância, tanto do efeito quanto dos coeficientes. O coeficiente de determinação de 60.36 % também indica um ajuste satisfatório. A dose ótima do nutriente pode ser encontrado através do ponto de máximo do modelo quadrático considerando o intervalo dos níveis analisados, isto é, de 0 a 75. Cuidado com extrapolações, uma vez que o experimento não contempla doses fora do intervalo analisado. 6.4 O caso desbalanceado Experimentos desbalanceados são muito comuns na área das ciências agrárias. Isto ocorre principalmente devido à perda de parcelas ou unidades experimentais devido à contaminação, morte ou eventos não previstos. Voltaremos ao experimento em delineamento inteiramente casualizado, em que se avalia a resposta no desenvolvimento em altura das plantas de quatro níveis de um nutriente. Cada nível de nutriente foi repetido 6 vezes. Tratamento: 4 dosagens de um nutriente 6 repetições Variável de interesse: altura No entanto, perceba que duas medições foram perdidas por morte das plantas: dose 0 repetição 4 dose 75 repetição 2 Table 6.3: Dados de outro delineamento inteiramente casualizado, porém neste caso desbalanceado tratamento rep altura 0 1 32.3 0 2 50.6 0 3 50.6 0 5 37.1 0 6 26.3 25 1 46.3 25 2 50.3 25 3 47.5 25 4 45.6 25 5 63.9 25 6 36.3 50 1 68.5 50 2 93.9 50 3 96.5 50 4 77.7 50 5 77.7 50 6 68.8 75 1 26.3 75 3 37.7 75 4 35.1 75 5 33.9 75 6 26.3 O primeiro passo é importar o arquivo csv contendo os resultados do experimento para dentro do R. Esta tarefa pode ser realizada através do seguinte comando: dic3 = read.csv(&quot;./data/Experimento DIC 3.csv&quot;) Antes de chamar a análise estatística, recomenda-se explorar os dados graficamente. Por se tratar de um tratamento de níveis quantitativos, o gráfico de dispersão é mais adequado: plot(data = dic3, altura ~ tratamento) Mesmo se tratando de um experimento desbalanceado, por se tratar de um DIC e consequentemente não existir interações a serem calculadas, pode-se utilizar a ANOVA Tipo I. Com relação aos parâmetros opcionais, apenas o parâmetro quali precisa ser alterado para FALSE, por se tratar tratamento quantitativo: require(ExpDes.pt) dic(dic3$tratamento, dic3$altura, quali = FALSE) ## ------------------------------------------------------------------------ ## Quadro da analise de variancia ## ------------------------------------------------------------------------ ## GL SQ QM Fc Pr&gt;Fc ## Tratamento 3 7775.1 2 27.056 6.8921e-07 ## Residuo 18 1724.2 3 ## Total 21 9499.3 1 ## ------------------------------------------------------------------------ ## CV = 19.07 % ## ## ------------------------------------------------------------------------ ## Teste de normalidade dos residuos ## Valor-p: 0.1497467 ## De acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais. ## ------------------------------------------------------------------------ ## ## ------------------------------------------------------------------------ ## Teste de homogeneidade de variancia ## valor-p: 0.4610355 ## De acordo com o teste de bartlett a 5% de significancia, as variancias podem ser consideradas homogeneas. ## ------------------------------------------------------------------------ ## ## Ajuste de modelos polinomiais de regressao ## ------------------------------------------------------------------------ ## ## Modelo Linear ## ========================================= ## Estimativa Erro.padrao tc valor.p ## ----------------------------------------- ## b0 48.9626 3.5785 13.6823 0 ## b1 0.0631 0.0775 0.8134 0.4266 ## ----------------------------------------- ## ## R2 do modelo linear ## -------- ## 0.008151 ## -------- ## ## Analise de variancia do modelo linear ## =========================================================== ## GL SQ QM Fc valor.p ## ----------------------------------------------------------- ## Efeito linear 1 63.3741 63.3741 0.66 0.42662 ## Desvios de Regressao 2 7,711.6930 3,855.8460 40.25 0 ## Residuos 18 1,724.1970 95.7887 ## ----------------------------------------------------------- ## ------------------------------------------------------------------------ ## ## Modelo quadratico ## ========================================= ## Estimativa Erro.padrao tc valor.p ## ----------------------------------------- ## b0 33.2553 4.2463 7.8316 0 ## b1 1.7909 0.2631 6.8063 0 ## b2 -0.0230 0.0034 -6.8717 0 ## ----------------------------------------- ## ## R2 do modelo quadratico ## -------- ## 0.589904 ## -------- ## ## Analise de variancia do modelo quadratico ## =========================================================== ## GL SQ QM Fc valor.p ## ----------------------------------------------------------- ## Efeito linear 1 63.3741 63.3741 0.66 0.42662 ## Efeito quadratico 1 4,523.1710 4,523.1710 47.22 0 ## Desvios de Regressao 1 3,188.5220 3,188.5220 33.29 2e-05 ## Residuos 18 1,724.1970 95.7887 ## ----------------------------------------------------------- ## ------------------------------------------------------------------------ ## ## Modelo cubico ## ========================================= ## Estimativa Erro.padrao tc valor.p ## ----------------------------------------- ## b0 39.3800 4.3770 8.9971 0 ## b1 -1.4961 0.6275 -2.3840 0.0283 ## b2 0.1019 0.0219 4.6503 0.0002 ## b3 -0.0011 0.0002 -5.7695 0.00002 ## ----------------------------------------- ## ## R2 do modelo cubico ## - ## 1 ## - ## ## Analise de variancia do modelo cubico ## =========================================================== ## GL SQ QM Fc valor.p ## ----------------------------------------------------------- ## Efeito linear 1 63.3741 63.3741 0.66 0.42662 ## Efeito quadratico 1 4,523.1710 4,523.1710 47.22 0 ## Efeito cubico 1 3,188.5220 3,188.5220 33.29 2e-05 ## Desvios de Regressao 0 0 0 0 1 ## Residuos 18 1,724.1970 95.7887 ## ----------------------------------------------------------- ## ------------------------------------------------------------------------ "],["delineamento-em-blocos-casualizados.html", "Cap. 7 Delineamento em blocos casualizados 7.1 O caso balanceado 7.2 O caso desbalanceado", " Cap. 7 Delineamento em blocos casualizados Nos experimentos em blocos casualizados (DBC), além do tratamento uma segunda fonte de variação controlada é inserida no modelo e é denominada de bloco. O bloco é inserido pelo analista para controlar uma variação esperada do ambiente, como por exemplo tipo de solo, insolação e outros. Assim a ANOVA contará com três fontes de variação: duas fontes de variação conhecidas determinada pelo tratamento e pelo bloco, e uma fonte de variação desconhecida determinada pelo resíduo. Vale destacar, que no DBC, não há interesse pela interação do bloco com o tratamento, sendo o bloco apenas para controlar uma possível variação sobre os tratamentos induzida por uma possível variação do ambiente. O modelo estatístico do delineamento em blocos casualizados é: \\[Y = Xmed + BLOCO + TRAT + Erro\\] A análise começa pela determinação das somas de quadrados total, composta pela soma de quadrados do tratamento, pela soma de quadrados do bloco e pela soma de quadrados do resíduo. Em seguida, calculam-se os quadrados médios do tratamento e do resíduo e o valor da estatística F. Se F calculado for superior ao F tabelado, assume-se que existe um efeito devido aos tratamentos, ao passo que se F calculado for inferior ao F tabelado, não há evidências suficientes para rejeitar a hipótese nula, aceitando-se a hipótese de que não existe efeito dos tratamentos. Embora em alguns softwares o teste F para o bloco seja realizado, o mesmo não é necessário. O utilidade do bloco é é apenas isolar uma possível variação atribuída ao ambiente. Uma vez que tenha optado pelo uso do bloco, é irrelevante encontrar sua significância (ou não significância) , uma vez que não será alterado o design da análise. Sendo o efeito dos tratamentos significativo, realiza-se o desdobramento do efeito dos tratamentos através de um teste de médias se os tratamentos forem qualitativos, ou uma análise de regressão se os tratamentos forem quantitativos. Para a análise de experimentos em blocos casualizados, como não há no modelo estatístico a influência da interação, utiliza-se o pacote ExpDes.pt tanto para o caso balanceado, quanto para o desbalanceado. 7.1 O caso balanceado Para exemplificar o caso balanceado, será analisado um estudo sobre a influência de duas intensidades de desbaste no diâmetro de árvores. Os desbastes foram repetidos em 4 parcelas para cada um dos cinco blocos. Os blocos foram considerados para isolar o efeito dos diferentes tipos de solo. Os dados podem ser resumidos através dos seguintes tópicos: Tratamento: 2 intensidades de desbaste (30% e 50%) 5 Blocos 4 repetições Variável de interesse: diâmetro Table 7.1: Dados de delineamento em blocos casualizado desbaste bloco rep diametro 30 1 1 28.37041 30 1 2 29.28010 30 1 3 30.84926 30 1 4 27.89227 30 2 1 20.38856 30 2 2 21.47290 30 2 3 24.39744 30 2 4 24.65861 30 3 1 23.79856 30 3 2 25.69388 30 3 3 24.45922 30 3 4 27.94071 30 4 1 28.05501 30 4 2 26.42934 30 4 3 23.09124 30 4 4 22.54273 30 5 1 32.73052 30 5 2 29.17538 30 5 3 29.94747 30 5 4 29.35810 50 1 1 31.20701 50 1 2 40.85273 50 1 3 33.66891 50 1 4 33.15001 50 2 1 34.03869 50 2 2 36.24517 50 2 3 35.49081 50 2 4 31.58952 50 3 1 31.92634 50 3 2 28.82107 50 3 3 32.18963 50 3 4 31.55686 50 4 1 31.11534 50 4 2 31.05093 50 4 3 34.69215 50 4 4 32.95378 50 5 1 25.26880 50 5 2 30.48375 50 5 3 31.73922 50 5 4 26.21619 O primeiro passo é importar o arquivo csv contendo os resultados do experimento para dentro do R. Esta tarefa pode ser realizada através do seguinte comando: dbc1 = read.csv(&quot;./data/Experimento DBC 1.csv&quot;) Antes de partir para a análise, é fundamental explorar os dados de forma gráfica para conhecer melhor os dados e antecipar o resultado da análise estatística. A construção do gráfico ajuda na compreensão do fenômeno estudado e na validação da análise estatística escolhida. Por se tratar de um experimento com o tratamento formado por níveis qualitativos, recomenda-se o uso do boxplot(). boxplot(data = dbc1, diametro ~ desbaste/bloco) Note que os rótulo do eixo X são compostos pela união no desbaste e do bloco. Pode ser que dependendo do espaço disponível alguns rótulos sejam omitidos, mas ele devem ser lidos alternadamente, uma caixa para 30.1, outra para 50.1, depois 30.2, seguido de 50.2 e assim por diante. Os tratamentos podem ser analisados isoladamente em relação a cada bloco, utilizando um filtro para escolher qual bloco considerar. # Para bloco igual a 1 boxplot(data = dbc1[dbc1$bloco == 1,], diametro~desbaste/bloco) # Para bloco igual a 2 boxplot(data = dbc1[dbc1$bloco == 2,], diametro~desbaste/bloco) # Para bloco igual a 3 boxplot(data = dbc1[dbc1$bloco == 3,], diametro~desbaste/bloco) # Para bloco igual a 4 boxplot(data = dbc1[dbc1$bloco == 4,], diametro~desbaste/bloco) # Para bloco igual a 5 boxplot(data = dbc1[dbc1$bloco == 5,], diametro~desbaste/bloco) Pelo gráfico obtido, é razoável esperar que haja diferenças significativas entre as intensidades de desbaste (30% e 50%), pois existe um distanciamento entre os interquartis especialmente nos blocos 1 e 2. Também é possível esperar que não haja um efeito significativo dos blocos. Assim, espera-se que a análise estatística do experimento corrobore a conclusão empírica baseada no interpretação do gráfico. Com a função dbc() do pacote ExpDes.pt será possível realizar toda a análise de um experimento de delineamento em blocos casualizados, inclusive desdobramentos. Toda função no R tem uma sintaxe que pode ser consultada digitando no console ? seguido do nome da função: ?dbc Nas informações sobre a função ?dbc, você verá que a sintaxe básica da função dbc() é: dbc(trat, bloco, resp, quali = TRUE, mcomp = &quot;tukey&quot;, sigT = 0.05, sigF = 0.05) A análise do experimento em questão pode ser então realizada pelo comando: require(ExpDes.pt) dbc(dbc1$desbaste, dbc1$bloco, dbc1$diametro, hvar=&#39;han&#39;) ## ------------------------------------------------------------------------ ## Quadro da analise de variancia ## ------------------------------------------------------------------------ ## GL SQ QM Fc Pr&gt;Fc ## Tratamento 1 323.34 4 30.4546 0.000004 ## Bloco 4 69.49 3 1.6363 0.187727 ## Residuo 34 360.98 2 ## Total 39 753.80 1 ## ------------------------------------------------------------------------ ## CV = 11.09 % ## ## ------------------------------------------------------------------------ ## Teste de normalidade dos residuos ## valor-p: 0.9155415 ## De acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais. ## ------------------------------------------------------------------------ ## ## ------------------------------------------------------------------------ ## Teste de homogeneidade de variancia ## valor-p: 0.3001718 ## De acordo com o teste de han a 5% de significancia, as variancias podem ser consideradas homogeneas. ## ------------------------------------------------------------------------ ## ## Teste de Tukey ## ------------------------------------------------------------------------ ## Grupos Tratamentos Medias ## a 50 32.21285 ## b 30 26.52659 ## ------------------------------------------------------------------------ A interpretação da saída de um delineamento em blocos casualizados é muito parecido com os experimento em DIC. A inclusão do bloco como fonte de variação, não trás nenhuma implicação já que o bloco visa apenas isolar um potencial efeito do ambiente não controlado durante a instalação do experimento. Neste primeiro exemplo, os resíduos apresentaram normalidade e o efeito dos tratamentos foi significativo. Como existem apenas dois tratamento, a significância do teste F já é conclusivo. De qualquer forma, a função dbc() realiza também um teste de médias que apenas reforça o resultado do teste F, indicando que o grupo a obteve média maior que o grupo b. 7.2 O caso desbalanceado Embora o delineamento em blocos casualizados, tenha além do tratamento, o efeito do bloco, estes são analisados de forma independente sem considerar a interação entre eles. A rigor, a definição de blocos visa apenas controlar uma fonte de variação não controlada pelo experimento, e não inferir sobre seu efeito. Desta forma, por não haver interação, o caso de DBC desbalanceado pode ser analisado através da ANOVA do Tipo I. Neste exemplo, usaremos o mesmo exemplo anterior, mas assumindo que foi perdida uma parcela devido à um incêndio: a repetição 1, do bloco 2 do tratamento intensidade de desbaste de 30%: Tratamento: 2 intensidades de desbaste 5 Blocos 4 repetições Variável de interesse: diâmetro Parcela perdida: Tratamento 30, Bloco 2, Repetição 1. Table 7.2: Dados de outro delineamento em blocos casualizado, porém neste caso desbalanceado. desbaste bloco rep diametro 30 1 1 28.37041 30 1 2 29.28010 30 1 3 30.84926 30 1 4 27.89227 30 2 2 21.47290 30 2 3 24.39744 30 2 4 24.65861 30 3 1 23.79856 30 3 2 25.69388 30 3 3 24.45922 30 3 4 27.94071 30 4 1 28.05501 30 4 2 26.42934 30 4 3 23.09124 30 4 4 22.54273 30 5 1 32.73052 30 5 2 29.17538 30 5 3 29.94747 30 5 4 29.35810 50 1 1 31.20701 50 1 2 40.85273 50 1 3 33.66891 50 1 4 33.15001 50 2 1 34.03869 50 2 2 36.24517 50 2 3 35.49081 50 2 4 31.58952 50 3 1 31.92634 50 3 2 28.82107 50 3 3 32.18963 50 3 4 31.55686 50 4 1 31.11534 50 4 2 31.05093 50 4 3 34.69215 50 4 4 32.95378 50 5 1 25.26880 50 5 2 30.48375 50 5 3 31.73922 50 5 4 26.21619 O primeiro passo é importar o arquivo csv contendo os resultados do experimento para dentro do R. Esta tarefa pode ser realizada através do seguinte comando: dbc2 = read.csv(&quot;./data/Experimento DBC 2.csv&quot;) Mesmo no caso desbalanceado, a análise gráfica é fundamental e deve preceder qualquer análise estatística: boxplot(data = dbc2, diametro ~ desbaste/bloco) Os tratamentos podem ser analisados isoladamente em relação a cada bloco, utilizando um filtro para escolher qual bloco considerar. # Para bloco igual a 1 boxplot(data = dbc2[dbc2$bloco == 1,], diametro~desbaste/bloco) # Para bloco igual a 2 boxplot(data = dbc2[dbc2$bloco == 2,], diametro~desbaste/bloco) # Para bloco igual a 3 boxplot(data = dbc2[dbc2$bloco == 3,], diametro~desbaste/bloco) # Para bloco igual a 4 boxplot(data = dbc2[dbc2$bloco == 4,], diametro~desbaste/bloco) # Para bloco igual a 5 boxplot(data = dbc2[dbc2$bloco == 5,], diametro~desbaste/bloco) Como já discutido anteriormente, por não haver cálculo de interação entre fontes de variação, o DBC pode ser analisado usando o pacote padrão ExpDes.pt e sua função dbc(): require(ExpDes.pt) dbc(dbc2$desbaste, dbc2$bloco, dbc2$diametro, hvar=&#39;han&#39;) ## ------------------------------------------------------------------------ ## Quadro da analise de variancia ## ------------------------------------------------------------------------ ## GL SQ QM Fc Pr&gt;Fc ## Tratamento 1 280.26 3 28.2071 0.000007 ## Bloco 4 62.92 2 1.5832 0.201872 ## Residuo 33 327.89 4 ## Total 38 671.07 1 ## ------------------------------------------------------------------------ ## CV = 10.65 % ## ## ------------------------------------------------------------------------ ## Teste de normalidade dos residuos ## valor-p: 0.9523324 ## De acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais. ## ------------------------------------------------------------------------ ## ## ------------------------------------------------------------------------ ## Teste de homogeneidade de variancia ## valor-p: 0.3579419 ## De acordo com o teste de han a 5% de significancia, as variancias podem ser consideradas homogeneas. ## ------------------------------------------------------------------------ ## ## Teste de Tukey ## ------------------------------------------------------------------------ ## Grupos Tratamentos Medias ## a 50 32.21285 ## b 30 26.84964 ## ------------------------------------------------------------------------ O teste de Shapiro-Wilk não aponta evidências para rejeitar a hipótese de normalidade de resíduos e portanto o modelo estatístico de blocos casualizados é considerado adequado. "],["fatorial-duplo-inteiramento-casualizado.html", "Cap. 8 Fatorial duplo inteiramento casualizado 8.1 O caso balanceado 8.2 O caso desbalanceado", " Cap. 8 Fatorial duplo inteiramento casualizado Os experimentos fatoriais podem ocorrer de maneira inteiramente casualizado ou em blocos casualizados. No caso de um fatorial inteiramente casualizado, a ANOVA contará com quatro fontes de variação: uma fonte de variação conhecida determinada pelo tratamento A, outra fonte de variação conhecida determinada pelo tratamento B, outra fonte de variação conhecida determinada pela interação entre os dois tratamentos e uma quarta fonte de variação desconhecida determinada pelo resíduo. O modelo estatístico do delineamento fatorial duplo inteiramente casualizado é: \\[Y = Xmed + TRAT A + TRAT B + (TRAT A * TRAT B) + Erro\\] A análise começa pela determinação das somas de quadrados total, composta pela soma de quadrados do fator 1, pela soma de quadrados do fator 2, pela soma de quadrados da interação dos dois fatores e pela soma de quadrados do resíduo. Em seguida, calculam-se os quadrados médios do fator 1, fator 2, interação e do resíduo. A estatística F será computada para cada um dos fatores, bem como sua interação. Se F calculado for superior ao F tabelado, assume-se que existe um efeito devido ao respectivo fator (ou interação), ao passo que se F calculado for inferior ao F tabelado, não há evidências suficientes para rejeitar a hipótese nula, aceitando-se a hipótese de que não existe efeito do fator (ou interação). Sendo a interação significativa, parte-se direto para o desdobramento de um fator dentro do outro. Apenas no caso de interação não significativa, considera-se o desdobramento dos fatores isolados. 8.1 O caso balanceado Neste exemplo de delineamento inteiramente casualizado em esquema fatorial temos um experimento que avaliou o efeito de dois indutores de enraizamento em duas concentrações no enraizamento de estacas de uma espécie de árvore nativa do cerrado brasileiro. Os dados podem ser resumidos através dos seguintes tópicos: Fator 1: indutor A e indutor B Fator 2: Dose 10 e 20% 5 repetições Variável de interesse: número médio de raízes Table 8.1: Dados de experimento em fatorial em DIC indutor concentracao rep enraizamento A 10 1 7.4 A 10 2 6.7 A 10 3 4.6 A 10 4 7.4 A 10 5 6.0 A 20 1 6.7 A 20 2 8.9 A 20 3 5.3 A 20 4 1.5 A 20 5 4.6 B 10 1 0.7 B 10 2 1.5 B 10 3 0.0 B 10 4 0.0 B 10 5 1.5 B 20 1 0.0 B 20 2 0.0 B 20 3 2.3 B 20 4 0.0 B 20 5 0.0 O primeiro passo é importar o arquivo csv contendo os resultados do experimento para dentro do R. Esta tarefa pode ser realizada através do seguinte comando: fatDIC1 = read.csv(&quot;./data/Experimento Fatorial Duplo DIC 1.csv&quot;) Antes da análise estatística, exploramos os dados através dos gráficos boxplot() ou plot(). Com base nos dados do experimento em questão, vamos analisá-lo através de uma série de gráficos boxplot. Embora a concentração seja uma variável contínua, este fator possui apenas dois níveis e portanto não é suficiente para considerar uma análise de tendência utilizando regressão. # Considerando apenas fator 1 boxplot(data = fatDIC1, enraizamento ~ indutor) # Considerando apenas fator 2 boxplot(data = fatDIC1, enraizamento ~ concentracao) # Interação dos fatores boxplot(data = fatDIC1, enraizamento ~ indutor/concentracao) # Isolando os níveis do fator 2 # Fixando concentracao igual a 10 boxplot(data = fatDIC1[fatDIC1$concentracao == 10,], enraizamento ~ indutor) # Fixando concentracao igual a 20 boxplot(data = fatDIC1[fatDIC1$concentracao == 20,], enraizamento ~ indutor) # Isolando os níveis do fator 1 # Fixando Indutor igual a &#39;A&#39; boxplot(data = fatDIC1[fatDIC1$indutor == &quot;A&quot;,], enraizamento ~ concentracao) # Fixando Indutor igual a &#39;B&#39; boxplot(data = fatDIC1[fatDIC1$indutor == &quot;B&quot;,], enraizamento ~ concentracao) Com base nos gráficos, é razoável apontar que o fator Indutor apresentou maior variação do que o fator Concentração. A interação também não parece influenciar o comportamento já identificado pelos fatores, quando analisados isoladamente. A função do pacote ExpDes.pt para análise deste tipo de experimento é a fat2.dic(). A sintaxe desta função é: fat2.dic(fator1, fator2, resp, quali = c(TRUE, TRUE), mcomp = &quot;tukey&quot;, fac.names = c(&quot;F1&quot;, &quot;F2&quot;), sigT = 0.05, sigF = 0.05) Ajustando com base nos dados do experimento, o comando fica: require(ExpDes.pt) fat2.dic(fatDIC1$indutor, fatDIC1$concentracao, fatDIC1$enraizamento, quali = c(TRUE, TRUE), fac.names = c(&quot;Indutor&quot;, &quot;Concentração&quot;)) ## ------------------------------------------------------------------------ ## Legenda: ## FATOR 1: Indutor ## FATOR 2: Concentração ## ------------------------------------------------------------------------ ## ## ## Quadro da analise de variancia ## ------------------------------------------------------------------------ ## GL SQ QM Fc Pr&gt;Fc ## Indutor 1 140.981 3 54.000 0.00000 ## Concentração 1 2.113 4 0.809 0.38171 ## Indutor*Concentração 1 0.684 2 0.262 0.61562 ## Residuo 16 41.772 5 ## Total 19 185.550 1 ## ------------------------------------------------------------------------ ## CV = 49.64 % ## ## ------------------------------------------------------------------------ ## Teste de normalidade dos residuos (Shapiro-Wilk) ## valor-p: 0.144 ## De acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais. ## ------------------------------------------------------------------------ ## ## Interacao nao significativa: analisando os efeitos simples ## ------------------------------------------------------------------------ ## Indutor ## Teste de Tukey ## ------------------------------------------------------------------------ ## Grupos Tratamentos Medias ## a A 5.91 ## b B 0.6 ## ------------------------------------------------------------------------ ## ## Concentração ## De acordo com o teste F, as medias desse fator sao estatisticamente iguais. ## ------------------------------------------------------------------------ ## Niveis Medias ## 1 10 3.58 ## 2 20 2.93 ## ------------------------------------------------------------------------ O teste Shapiro-Wilk indica que os resíduos podem ser considerados normais. Assim, o modelo estatístico é adequado e os demais resultados podem ser considerados e analisados. A interação foi não significativa, e portanto os fatores devem ser analisados de forma independente. Apenas o fator Indutor foi significativo, levando então a um desdobramento dos níveis, que indica uma média do Indutor A superior à média do Indutor B. 8.2 O caso desbalanceado Neste exemplo de delineamento inteiramente casualizado em esquema fatorial, com dados desbalanceados, temos um experimento para avaliar o enraizamento de dois tipos de substratos e duas intensidades de irrigação. Infelizmente, uma das bandejas de enraizamento foi contaminada e com fungo e portanto foi considerada perdida. Por isto, este experimento é considerado desbalanceado. Os dados podem ser resumidos através dos seguintes tópicos: Fator 1: substrato A e B Fator 2: intensidade de irrigação 10 mm e 20 mm 5 repetições Informação perdida: Repetição 5 do substrato A, intensidade de irrigação 10 mm Variável de interesse: número médio de raízes Table 8.2: Dados de experimento em fatorial em DIC, porém desbalanceado. substrato irrigacao rep enraizamento A 10 1 7.4 A 10 2 6.7 A 10 3 4.6 A 10 4 7.4 A 20 1 6.7 A 20 2 8.9 A 20 3 5.3 A 20 4 1.5 A 20 5 4.6 B 10 1 0.7 B 10 2 1.5 B 10 3 0.0 B 10 4 0.0 B 10 5 1.5 B 20 1 0.0 B 20 2 0.0 B 20 3 2.3 B 20 4 0.0 B 20 5 0.0 O primeiro passo é importar o arquivo csv contendo os resultados do experimento para dentro do R. Esta tarefa pode ser realizada através do seguinte comando: fatDIC2 = read.csv(&quot;./data/Experimento Fatorial Duplo DIC 2.csv&quot;, sep = &quot;,&quot;, dec = &quot;.&quot;) Assim como no caso balanceado, é fundamental analisar os dados do experimento em gráficos e buscar antecipar os resultados que serão obtidos no teste estatístico. Os mesmo gráficos do exemplo balanceado podem ser utilizados: # Considerando apenas fator 1 boxplot(data = fatDIC2, enraizamento ~ substrato) # Considerando apenas fator 2 boxplot(data = fatDIC2, enraizamento ~ irrigacao) # Interação dos fatores boxplot(data = fatDIC2, enraizamento ~ substrato/irrigacao) # Isolando os níveis do fator 2 # Fixando concentracao igual a 10 boxplot(data = fatDIC2[fatDIC2$irrigacao == 10,], enraizamento ~ substrato) # Fixando concentracao igual a 20 boxplot(data = fatDIC2[fatDIC2$irrigacao == 20,], enraizamento ~ substrato) # Isolando os níveis do fator 1 # Fixando Indutor igual a &#39;A&#39; boxplot(data = fatDIC2[fatDIC2$substrato == &quot;A&quot;,], enraizamento ~ irrigacao) # Fixando Indutor igual a &#39;B&#39; boxplot(data = fatDIC2[fatDIC2$substrato == &quot;B&quot;,], enraizamento ~ irrigacao) Os gráficos mostram que é razoável apontar que o fator substrato apresentou maior variação do que o fator irrigacao. Na mesma linha do exemplo anterior, a interação também não parece influenciar o comportamento já identificado pelos fatores, quando analisados isoladamente. Sendo o nosso experimento desbalanceado, a função para rodar a ANOVA do tipo III é o ea2() (do pacote easyanova). A sintaxe da função é: ea2(data, design = 1, alpha = 0.05, cov = 4, list = FALSE, p.adjust=1, plot=2) Como já mencionado, o pacote easyanova exige que os dados sejam apresentados numa forma específica contendo apenas as colunas relevantes para a análise. No caso de um experimento fatorial duplo inteiramente casualizado, a ordem esperada das colunas é: Fator A Fator B Repetição Variável resposta Considerando as colunas substrato, irrigacao e enraizamento do dataframe fatDIC2. Os demais parâmetros da função ea2() serão definidos como design = 1 e plot = 2. require(easyanova) r.aov = ea2(fatDIC2[, c(1, 2, 4)], design = 1) A saída da função ea2() é uma lista contendo os seguintes resultados: names(r.aov) ## [1] &quot;Analysis of variance&quot; ## [2] &quot;Adjusted means (factor 1)&quot; ## [3] &quot;Multiple comparison test (factor 1)&quot; ## [4] &quot;Adjusted means (factor 2)&quot; ## [5] &quot;Multiple comparison test (factor 2)&quot; ## [6] &quot;Adjusted means (factor 1 in levels of factor 2)&quot; ## [7] &quot;Multiple comparison test (factor 1 in levels of factor 2)&quot; ## [8] &quot;Adjusted means (factor 2 in levels of factor 1)&quot; ## [9] &quot;Multiple comparison test (factor 2 in levels of factor 1)&quot; ## [10] &quot;Residual analysis&quot; A lista acima contém os seguintes resultados: Análise de variância Comparação de médias do fator 1 Teste de comparação múltipla do fator 1 Comparação de médias do fator 2 Teste de comparação múltipla do fator 2 Comparação de médias do fator 1 dentro dos níveis do fator 2 Teste de comparação múltipla do fator 1 dentro dos níveis do fator 2 Comparação de médias do fator 2 dentro dos níveis do fator 1 Teste de comparação múltipla do fator 2 dentro dos níveis do fator 1 Análise das pressuposições A primeira saída que deve ser verificada é a análise das pressuposição, na posição 10 da lista: r.aov[10] ## $`Residual analysis` ## $`Residual analysis`$`residual analysis` ## values ## p.value Shapiro-Wilk test 0.2084 ## p.value Bartlett test (factor_1) 0.0146 ## p.value Bartlett test (factor_2) 0.0610 ## p.value Bartlett test (treatments) 0.0765 ## coefficient of variation (%) 53.5100 ## first value most discrepant 8.0000 ## second value most discrepant 6.0000 ## third value most discrepant 3.0000 ## ## $`Residual analysis`$residuals ## 1 2 3 4 5 6 7 8 9 10 11 ## 0.875 0.175 -1.925 0.875 1.300 3.500 -0.100 -3.900 -0.800 -0.040 0.760 ## 12 13 14 15 16 17 18 19 ## -0.740 -0.740 0.760 -0.460 -0.460 1.840 -0.460 -0.460 ## ## $`Residual analysis`$`standardized residuals` ## 1 2 3 4 5 6 ## 0.57590514 0.11518103 -1.26699130 0.57590514 0.85563049 2.30362055 ## 7 8 9 10 11 12 ## -0.06581773 -2.56689147 -0.52654184 -0.02632709 0.50021475 -0.48705120 ## 13 14 15 16 17 18 ## -0.48705120 0.50021475 -0.30276156 -0.30276156 1.21104623 -0.30276156 ## 19 ## -0.30276156 O teste de normalidade Shapiro-Wilk indica que não há evidência suficientes para rejeitar a pressuposição de normalidade do modelo estatístico e portanto, este é adequado para representar o experimento analisado. Desta forma, a análise de variância contido na posição 1 da lista de resultados pode ser analisado: r.aov[1] ## $`Analysis of variance` ## df type III SS mean square F value p&gt;F ## factor_1 1 135.3243 135.3243 48.8518 &lt;0.001 ## factor_2 1 2.3224 2.3224 0.8384 0.3743 ## factor_1:factor_2 1 0.8400 0.8400 0.3032 0.59 ## residuals 15 41.5515 2.7701 - - O fator 1 (Indutor) foi altamente significativo, apresentando teste F inferior a 1%. Já o fator 2 (Concentração), bem como a interação não foram significativas. Como a interação não foi significativa, não há necessidade de desdobramento, e o fator 1 - Indutor pode ser analisado diretamente. Lembrando que no exemplo apresentado, o fator 1 possui apenas dois níveis e portanto o teste F é conclusivo. De qualquer maneira, o teste de médias do fator 1 pode ser obtido na posição 2 da lista de resultado. r.aov[2] ## $`Adjusted means (factor 1)` ## factor_1 adjusted.mean standard.error tukey snk duncan t scott_knott ## 1 A 5.9625 0.5582 a a a a a ## 2 B 0.6000 0.5263 b b b b b "],["fatorial-duplo-em-blocos-casualizados.html", "Cap. 9 Fatorial duplo em blocos casualizados 9.1 O caso balanceado 9.2 O caso desbalanceado", " Cap. 9 Fatorial duplo em blocos casualizados No caso de um fatorial duplo em blocos casualizados, a ANOVA contará com cinco fontes de variação: uma fonte de variação conhecida atribuída ao bloco, outra fonte de variação conhecida determinada pelo tratamento A, outra fonte de variação conhecida determinada pelo tratamento B, outra fonte de variação conhecida determinada pela interação entre os dois tratamentos e uma quinta fonte de variação desconhecida determinada pelo resíduo. O modelo estatístico do delineamento fatorial duplo inteiramente casualizado é: \\[Y = Xmed + BLOCO + TRAT A + TRAT B + (TRAT A * TRAT B) + Erro\\] De forma semelhante ao experimento fatorial inteiramente casualizado, o caso balanceado será analisado através do pacote ExpDes.pt (função fat2.dbc()). Já o caso desbalanceado será analisado pelo pacote easyanova (função ea2() e design=2). 9.1 O caso balanceado O exemplo balanceado trata de um experimento no qual se avalia a altura de um experimento fatorial combinando cinco doses de um adubo nitrogenado com três espécies de árvores nativas da Mata Atlântica, organizados em 10 blocos: Fator 1: Doses de adubos 0, 25, 50, 75 e 100 Fator 2: Espécies 2, 5 e 7 10 blocos Variável de interesse: altura das plantas Table 9.1: Dados de experimento em fatorial DBC dose especie bloco altura 100 2 1 27.01093 100 2 2 24.67664 100 2 3 20.25999 100 2 4 23.98435 100 2 5 21.68730 100 2 6 27.95062 100 2 7 21.72693 100 2 8 23.81819 100 2 9 27.20599 100 2 10 22.71426 75 2 1 23.59123 75 2 2 22.25759 75 2 3 22.05516 75 2 4 20.04109 75 2 5 19.14948 75 2 6 22.95754 75 2 7 26.94884 75 2 8 22.74460 75 2 9 23.71342 75 2 10 24.38227 50 2 1 26.91505 50 2 2 19.72285 50 2 3 20.55555 50 2 4 24.44992 50 2 5 21.59082 50 2 6 24.56422 50 2 7 21.44374 50 2 8 20.99752 50 2 9 21.44592 50 2 10 24.29815 25 2 1 24.58642 25 2 2 22.54323 25 2 3 25.88379 25 2 4 23.48752 25 2 5 24.38289 25 2 6 24.72294 25 2 7 26.58771 25 2 8 22.46470 25 2 9 25.58907 25 2 10 20.94828 0 2 1 29.28761 0 2 2 24.83846 0 2 3 21.91967 0 2 4 25.25512 0 2 5 23.20428 0 2 6 22.30722 0 2 7 28.45246 0 2 8 25.35863 0 2 9 23.99814 0 2 10 28.78995 100 5 1 33.49074 100 5 2 37.72860 100 5 3 37.97029 100 5 4 39.65706 100 5 5 38.07058 100 5 6 38.46334 100 5 7 37.21368 100 5 8 40.00952 100 5 9 34.51427 100 5 10 38.46156 75 5 1 32.64211 75 5 2 42.87033 75 5 3 35.50921 75 5 4 34.52205 75 5 5 31.95030 75 5 6 40.25084 75 5 7 37.94206 75 5 8 41.28099 75 5 9 37.70441 75 5 10 39.68077 50 5 1 32.82667 50 5 2 31.92334 50 5 3 33.38743 50 5 4 29.40074 50 5 5 35.69536 50 5 6 38.64929 50 5 7 35.42279 50 5 8 34.72498 50 5 9 37.29969 50 5 10 35.06832 25 5 1 33.39860 25 5 2 39.56000 25 5 3 33.79608 25 5 4 33.88220 25 5 5 32.77403 25 5 6 31.14461 25 5 7 32.67330 25 5 8 31.84332 25 5 9 36.28326 25 5 10 35.10899 0 5 1 35.81985 0 5 2 36.19184 0 5 3 33.15076 0 5 4 33.92754 0 5 5 34.88189 0 5 6 34.25457 0 5 7 32.33597 0 5 8 31.39240 0 5 9 34.48195 0 5 10 35.83106 100 7 1 47.71383 100 7 2 45.75887 100 7 3 46.42036 100 7 4 44.89556 100 7 5 45.16561 100 7 6 44.48361 100 7 7 42.32970 100 7 8 49.53137 100 7 9 49.66715 100 7 10 47.61306 75 7 1 42.71420 75 7 2 42.74941 75 7 3 41.76867 75 7 4 44.32072 75 7 5 43.60612 75 7 6 38.70690 75 7 7 45.79070 75 7 8 42.08179 75 7 9 46.88940 75 7 10 45.78247 50 7 1 42.39296 50 7 2 38.98789 50 7 3 40.60666 50 7 4 39.63895 50 7 5 41.79340 50 7 6 42.35532 50 7 7 39.21753 50 7 8 41.16574 50 7 9 37.56872 50 7 10 43.35592 25 7 1 48.19243 25 7 2 43.00286 25 7 3 48.00344 25 7 4 40.75832 25 7 5 39.65651 25 7 6 46.13281 25 7 7 39.76537 25 7 8 43.41116 25 7 9 42.23041 25 7 10 40.82259 0 7 1 36.07182 0 7 2 43.15407 0 7 3 43.32585 0 7 4 37.79503 0 7 5 41.04694 0 7 6 44.91720 0 7 7 34.90952 0 7 8 42.47311 0 7 9 36.70185 0 7 10 38.83515 O primeiro passo é importar o arquivo csv contendo os resultados do experimento para dentro do R. Esta tarefa pode ser realizada através do seguinte comando: fatDBC1 = read.csv(&quot;./data/Experimento Fatorial Duplo DBC 1.csv&quot;, sep = &quot;,&quot;, dec = &quot;.&quot;) Para explorar este experimento graficamente, tanto a função boxplot() quanto a função plot() serão usadas. Isto ocorre porque temos um fator quantitativo (doses) e outro fator qualitativos (espécies). Assim, sempre que estivermos analisando o efeito das doses, devemos utilizar gráficos de dispersão. Enquanto que ao analisarmos o efeito dos clones, o boxplot será mais indicado. # Considerando apenas fator 1 plot(data = fatDBC1, altura ~ dose) # Considerando apenas fator 2 boxplot(data = fatDBC1, altura ~ especie) # Interação dos fatores boxplot(data = fatDBC1, altura ~ especie/dose) # Efeito dos blocos boxplot(data = fatDBC1, altura ~ especie/bloco) boxplot(data = fatDBC1, altura ~ dose/bloco) # Isolando os níveis do fator 2 # Fixando especie igual a 2 plot(data = fatDBC1[fatDBC1$especie == 2,], altura ~ dose) # Fixando especie igual a 5 plot(data = fatDBC1[fatDBC1$especie == 5,], altura ~ dose) # Fixando especie igual a 7 plot(data = fatDBC1[fatDBC1$especie == 7,], altura ~ dose) # Isolando os níveis do fator 1 # Fixando dose igual a 0 boxplot(data = fatDBC1[fatDBC1$dose == 0,], altura ~ especie) # Fixando dose igual a 25 boxplot(data = fatDBC1[fatDBC1$dose == 25,], altura ~ especie) # Fixando dose igual a 50 boxplot(data = fatDBC1[fatDBC1$dose == 50,], altura ~ especie) # Fixando dose igual a 75 boxplot(data = fatDBC1[fatDBC1$dose == 75,], altura ~ especie) # Fixando dose igual a 100 boxplot(data = fatDBC1[fatDBC1$dose == 100,], altura ~ especie) Com base nos gráficos apresentados, é razoável acreditar que há um efeito significativo da espécie, mas não não fica muito evidente o efeito significativo da dose, da interação e do bloco. Nota-se que as doses possuem comportamentos diferentes, variando de uma tendência quadrática à uma tendência sigmoidal (cúbica). Note que quanto mais fatores e interações estiverem presentes em nosso experimento, mais complicado vai ficando a análise gráfica e também a análise estatística. E é por este motivo que desencoraja-se o uso de experimentos fatoriais triplos. Embora os pacotes de análise experimental possuam funções para experimentos fatoriais triplos, não apresentaremos exemplos aqui neste livro. Tente discutir um experimento fatorial triplo com efeito dos fatores, interações duplas e interação tripla significativa! A análise estatística será feita pela função fat2.dbc() do pacote ExpDes.pt. A sintaxe básica da função pode ser vista acessando a página de ajuda da função: fat2.dbc(fator1, fator2, bloco, resp, quali = c(TRUE, TRUE), mcomp = &quot;tukey&quot;, fac.names = c(&quot;F1&quot;, &quot;F2&quot;), sigT = 0.05, sigF = 0.05) Lembrando que como temos um fator quantitativo e um fator qualitativo, além dos parâmetros obrigatórios, será necessário ajustar o parâmetro quali: require(ExpDes.pt) fat2.dbc(fatDBC1$dose, fatDBC1$especie, fatDBC1$bloco, fatDBC1$altura, quali = c(FALSE, TRUE), fac.names = c(&quot;Dose&quot;, &quot;Espécie&quot;)) ## ------------------------------------------------------------------------ ## Legenda: ## FATOR 1: Dose ## FATOR 2: Espécie ## ------------------------------------------------------------------------ ## ## ## Quadro da analise de variancia ## ------------------------------------------------------------------------ ## GL SQ QM Fc Pr&gt;Fc ## Bloco 9 60.5 6 1.03 0.41738 ## Dose 4 212.6 4 8.16 0.00001 ## Espécie 2 9138.4 3 702.07 0.00000 ## Dose*Espécie 8 224.7 2 4.32 0.00013 ## Residuo 126 820.0 5 ## Total 149 10456.2 1 ## ------------------------------------------------------------------------ ## CV = 7.5 % ## ## ------------------------------------------------------------------------ ## Teste de normalidade dos residuos (Shapiro-Wilk) ## valor-p: 0.6115979 ## De acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais. ## ------------------------------------------------------------------------ ## ## ## ## Interacao significativa: desdobrando a interacao ## ------------------------------------------------------------------------ ## ## Desdobrando Dose dentro de cada nivel de Espécie ## ------------------------------------------------------------------------ ## ------------------------------------------------------------------------ ## Quadro da analise de variancia ## ------------------------------------------------------------------------ ## GL SQ QM Fc Pr.Fc ## Bloco 9 60.52166 6.72463 1.0333 0.4174 ## Espécie 2 9138.36405 4569.18202 702.069 0 ## Dose:Espécie 2 4 50.44803 12.61201 1.9379 0.1082 ## Dose:Espécie 5 4 128.29922 32.07481 4.9284 0.001 ## Dose:Espécie 7 4 258.52025 64.63006 9.9306 0 ## Residuo 126 820.02899 6.50817 ## Total 149 10456.18221 70.17572 ## ------------------------------------------------------------------------ ## ## ## ## Dose dentro do nivel 2 de Espécie ## ## De acordo com o teste F, as medias desse fator sao estatisticamente iguais. ## ------------------------------------------------------------------------ ## Niveis Medias ## 1 0 25.34115 ## 2 100 24.10352 ## 3 25 24.11965 ## 4 50 22.59837 ## 5 75 22.78412 ## ------------------------------------------------------------------------ ## ## ## Dose dentro do nivel 5 de Espécie ## ------------------------------------------------------------------------ ## Ajuste de modelos polinomiais de regressao ## ------------------------------------------------------------------------ ## ## Modelo Linear ## ========================================= ## Estimativa Erro.padrao tc valor.p ## ----------------------------------------- ## b0 33.5310 0.6249 53.6589 0 ## b1 0.0402 0.0102 3.9399 0.0001 ## ----------------------------------------- ## ## R2 do modelo linear ## -------- ## 0.787434 ## -------- ## ## Analise de variancia do modelo linear ## ======================================================== ## GL SQ QM Fc valor.p ## -------------------------------------------------------- ## Efeito linear 1 101.0272 101.0272 15.52 0.00013 ## Desvios de Regressao 3 27.2720 9.0907 1.4 0.24689 ## Residuos 126 820.0290 6.5082 ## -------------------------------------------------------- ## ------------------------------------------------------------------------ ## ## Modelo quadratico ## ========================================= ## Estimativa Erro.padrao tc valor.p ## ----------------------------------------- ## b0 33.9893 0.7592 44.7679 0 ## b1 0.0035 0.0360 0.0984 0.9217 ## b2 0.0004 0.0003 1.0628 0.2899 ## ----------------------------------------- ## ## R2 do modelo quadratico ## -------- ## 0.844730 ## -------- ## ## Analise de variancia do modelo quadratico ## ======================================================== ## GL SQ QM Fc valor.p ## -------------------------------------------------------- ## Efeito linear 1 101.0272 101.0272 15.52 0.00013 ## Efeito quadratico 1 7.3510 7.3510 1.13 0.28991 ## Desvios de Regressao 2 19.9210 9.9605 1.53 0.22043 ## Residuos 126 820.0290 6.5082 ## -------------------------------------------------------- ## ------------------------------------------------------------------------ ## ## Modelo cubico ## ========================================= ## Estimativa Erro.padrao tc valor.p ## ----------------------------------------- ## b0 34.3340 0.8010 42.8666 0 ## b1 -0.0953 0.0815 -1.1688 0.2447 ## b2 0.0031 0.0021 1.5092 0.1337 ## b3 -0.00002 0.00001 -1.3510 0.1791 ## ----------------------------------------- ## ## R2 do modelo cubico ## -------- ## 0.937316 ## -------- ## ## Analise de variancia do modelo cubico ## ======================================================== ## GL SQ QM Fc valor.p ## -------------------------------------------------------- ## Efeito linear 1 101.0272 101.0272 15.52 0.00013 ## Efeito quadratico 1 7.3510 7.3510 1.13 0.28991 ## Efeito cubico 1 11.8787 11.8787 1.83 0.17912 ## Desvios de Regressao 1 8.0423 8.0423 1.24 0.26841 ## Residuos 126 820.0290 6.5082 ## -------------------------------------------------------- ## ------------------------------------------------------------------------ ## ## ## Dose dentro do nivel 7 de Espécie ## ------------------------------------------------------------------------ ## Ajuste de modelos polinomiais de regressao ## ------------------------------------------------------------------------ ## ## Modelo Linear ## ========================================= ## Estimativa Erro.padrao tc valor.p ## ----------------------------------------- ## b0 40.1029 0.6249 64.1758 0 ## b1 0.0525 0.0102 5.1402 0 ## ----------------------------------------- ## ## R2 do modelo linear ## -------- ## 0.665151 ## -------- ## ## Analise de variancia do modelo linear ## ======================================================== ## GL SQ QM Fc valor.p ## -------------------------------------------------------- ## Efeito linear 1 171.9549 171.9549 26.42 0 ## Desvios de Regressao 3 86.5653 28.8551 4.43 0.00535 ## Residuos 126 820.0290 6.5082 ## -------------------------------------------------------- ## ------------------------------------------------------------------------ ## ## Modelo quadratico ## ========================================= ## Estimativa Erro.padrao tc valor.p ## ----------------------------------------- ## b0 40.7468 0.7592 53.6682 0 ## b1 0.0009 0.0360 0.0263 0.9790 ## b2 0.0005 0.0003 1.4930 0.1379 ## ----------------------------------------- ## ## R2 do modelo quadratico ## -------- ## 0.721267 ## -------- ## ## Analise de variancia do modelo quadratico ## ======================================================== ## GL SQ QM Fc valor.p ## -------------------------------------------------------- ## Efeito linear 1 171.9549 171.9549 26.42 0 ## Efeito quadratico 1 14.5073 14.5073 2.23 0.13793 ## Desvios de Regressao 2 72.0581 36.0290 5.54 0.00496 ## Residuos 126 820.0290 6.5082 ## -------------------------------------------------------- ## ------------------------------------------------------------------------ ## ## Modelo cubico ## ========================================= ## Estimativa Erro.padrao tc valor.p ## ----------------------------------------- ## b0 40.1520 0.8010 50.1305 0 ## b1 0.1715 0.0815 2.1037 0.0374 ## b2 -0.0042 0.0021 -2.0501 0.0424 ## b3 0.00003 0.00001 2.3315 0.0213 ## ----------------------------------------- ## ## R2 do modelo cubico ## -------- ## 0.858116 ## -------- ## ## Analise de variancia do modelo cubico ## ======================================================== ## GL SQ QM Fc valor.p ## -------------------------------------------------------- ## Efeito linear 1 171.9549 171.9549 26.42 0 ## Efeito quadratico 1 14.5073 14.5073 2.23 0.13793 ## Efeito cubico 1 35.3782 35.3782 5.44 0.02131 ## Desvios de Regressao 1 36.6798 36.6798 5.64 0.01911 ## Residuos 126 820.0290 6.5082 ## -------------------------------------------------------- ## ------------------------------------------------------------------------ ## ## ## ## Desdobrando Espécie dentro de cada nivel de Dose ## ------------------------------------------------------------------------ ## ------------------------------------------------------------------------ ## Quadro da analise de variancia ## ------------------------------------------------------------------------ ## GL SQ QM Fc Pr.Fc ## Bloco 9 60.52166 6.72463 1.0333 0.4174 ## Dose 4 212.55440 53.13860 8.1649 0 ## Espécie:Dose 0 2 1080.11237 540.05619 82.9813 0 ## Espécie:Dose 25 2 1820.84094 910.42047 139.8889 0 ## Espécie:Dose 50 2 1691.61319 845.80659 129.9608 0 ## Espécie:Dose 75 2 2258.11368 1129.05684 173.4831 0 ## Espécie:Dose 100 2 2512.39697 1256.19849 193.0188 0 ## Residuo 126 820.02899 6.50817 ## Total 149 10456.18221 70.17572 ## ------------------------------------------------------------------------ ## ## ## ## Espécie dentro do nivel 0 de Dose ## ------------------------------------------------------------------------ ## Teste de Tukey ## ------------------------------------------------------------------------ ## Grupos Tratamentos Medias ## a 7 39.92305 ## b 5 34.22678 ## c 2 25.34115 ## ------------------------------------------------------------------------ ## ## ## Espécie dentro do nivel 25 de Dose ## ------------------------------------------------------------------------ ## Teste de Tukey ## ------------------------------------------------------------------------ ## Grupos Tratamentos Medias ## a 7 43.19759 ## b 5 34.04644 ## c 2 24.11965 ## ------------------------------------------------------------------------ ## ## ## Espécie dentro do nivel 50 de Dose ## ------------------------------------------------------------------------ ## Teste de Tukey ## ------------------------------------------------------------------------ ## Grupos Tratamentos Medias ## a 7 40.70831 ## b 5 34.43986 ## c 2 22.59837 ## ------------------------------------------------------------------------ ## ## ## Espécie dentro do nivel 75 de Dose ## ------------------------------------------------------------------------ ## Teste de Tukey ## ------------------------------------------------------------------------ ## Grupos Tratamentos Medias ## a 7 43.44104 ## b 5 37.43531 ## c 2 22.78412 ## ------------------------------------------------------------------------ ## ## ## Espécie dentro do nivel 100 de Dose ## ------------------------------------------------------------------------ ## Teste de Tukey ## ------------------------------------------------------------------------ ## Grupos Tratamentos Medias ## a 7 46.35791 ## b 5 37.55796 ## c 2 24.10352 ## ------------------------------------------------------------------------ Uma vez que os dados apresentaram normalidade, o modelo estatístico escolhido é adequado e a ANOVA pode ser então considerada. Com exceção do efeito do bloco, todos apresentaram alta significância, incluindo a interação. Desta forma, os efeitos devem ser analisados em conjunto através do desdobramento. O pacote ExpDes.pt já realiza para você. Fique atento! Não esqueça de definir na função se os fatores são qualitativos ou quantitativos. Como vimos anteriormente, experimentos qualitativos são desdobrados com teste de médias dentro fixando um dos fatores, enquanto que fatores quantitativos são desdobrados através da análise de regressão fixando um dos fatores. 9.2 O caso desbalanceado O exemplo desbalanceado trata de um experimento no qual se avalia a influência da intensidade do combate contra um determinado inseto na produção de sementes em duas espécies arbóreas, organizadas em 10 blocos: Fator 1: Percentuais de combate 100, 50 e 0 Fator 2: Espécies 2 e 5 10 blocos Observação perdida: bloco 8 do combate 100 e espécie 2 Variável de interesse: peso de sementes produzidas em quilos Table 9.2: Dados de outro experimento em fatorial DBC combate especie bloco peso 100 2 1 21.6 100 2 2 23.6 100 2 3 27.6 100 2 4 22.3 100 2 5 24.1 100 2 6 19.9 100 2 7 22.7 100 2 9 23.3 100 2 10 22.6 50 2 1 22.5 50 2 2 22.8 50 2 3 21.8 50 2 4 25.8 50 2 5 21.8 50 2 6 24.0 50 2 7 19.2 50 2 8 20.3 50 2 9 21.0 50 2 10 21.0 0 2 1 30.0 0 2 2 25.8 0 2 3 27.8 0 2 4 26.1 0 2 5 28.9 0 2 6 34.1 0 2 7 23.9 0 2 8 29.5 0 2 9 21.4 0 2 10 30.5 100 5 1 36.0 100 5 2 40.5 100 5 3 37.5 100 5 4 33.0 100 5 5 38.3 100 5 6 37.5 100 5 7 37.5 100 5 8 39.0 100 5 9 36.0 100 5 10 40.5 50 5 1 32.8 50 5 2 35.7 50 5 3 32.4 50 5 4 37.5 50 5 5 35.9 50 5 6 34.2 50 5 7 40.5 50 5 8 33.2 50 5 9 27.5 50 5 10 32.9 0 5 1 34.5 0 5 2 33.0 0 5 3 37.5 0 5 4 37.5 0 5 5 34.5 0 5 6 28.5 0 5 7 30.0 0 5 8 34.5 0 5 9 34.5 0 5 10 46.5 O primeiro passo é importar o arquivo csv contendo os resultados do experimento para dentro do R. Esta tarefa pode ser realizada através do seguinte comando: fatDBC2 = read.csv(&#39;./data/Experimento Fatorial Duplo DBC 2.csv&#39;, sep = &quot;,&quot;, dec = &quot;.&quot;) Assim como no experimento balanceado, os dados devem ser explorados graficamente. Diversas opções podem ser utilizadas a partir do pacote gráfico básico. Veja alguns exemplos e tente tirar sua próprias conclusões sobre a análise do experimento que será feita logo em seguida: # Considerando apenas fator 1 plot(data = fatDBC2, peso ~ combate) # Considerando apenas fator 2 boxplot(data = fatDBC2, peso ~ especie) # Interação dos fatores boxplot(data = fatDBC2, peso ~ especie/combate) # Efeito dos blocos boxplot(data = fatDBC2, peso ~ especie/bloco) boxplot(data = fatDBC2, peso ~ combate/bloco) # Isolando os níveis do fator 2 # Fixando especie igual a 2 plot(data = fatDBC2[fatDBC2$especie == 2,], peso ~ combate) # Fixando especie igual a 5 plot(data = fatDBC2[fatDBC2$especie == 5,], peso ~ combate) # Isolando os níveis do fator 1 # Fixando combate igual a 0 boxplot(data = fatDBC2[fatDBC2$combate == 0,], peso ~ especie) # Fixando combate igual a 50 boxplot(data = fatDBC2[fatDBC2$combate == 50,], peso ~ especie) # Fixando combate igual a 100 boxplot(data = fatDBC2[fatDBC2$combate == 100,], peso ~ especie) Como o delineamento fatorial duplo em blocos casualizados pode ter a interação significativa, é fundamental considerar a análise através da ANOVA tipo III. A sintaxe da função é: ea2(data, design = 1, alpha = 0.05, cov = 4, list = FALSE, p.adjust=1,plot=2) Como já mencionado, o pacote easyanova exige que os dados sejam apresentados em forma de dataframe contendo apenas as colunas relevantes para a análise. No caso de um experimento fatorial duplo em blocos casualizados, a ordem esperada das colunas é: Fator A Fator B Bloco Variável resposta Qualquer variável extra deve ser removida dos dados e a ordem acima deve ser respeitada para o correto uso do pacote. Além de apresentar os dados na estrutura correta, o parâmetro design deve ser ajustado para 2, indicando fatorial duplo em blocos casualizados. require(easyanova) r.aov = ea2(fatDBC2, design = 2) Os resultados são armazenados numa lista de 10 posições, aqui salva numa variável denominada de r.aov. As 10 posições contém: Análise de variância Comparação de médias do fator 1 Teste de comparação múltipla do fator 1 Comparação de médias do fator 2 Teste de comparação múltipla do fator 2 Comparação de médias do fator 1 dentro dos níveis do fator 2 Teste de comparação múltipla do fator 1 dentro dos níveis do fator 2 Comparação de médias do fator 2 dentro dos níveis do fator 1 Teste de comparação múltipla do fator 2 dentro dos níveis do fator 1 Análise das pressuposições Nota-se que o teste de Shapiro-Wilk não é significativo, aceitando-se portanto o teste de nulidade: os resíduos são normais. r.aov[10] ## $`Residual analysis` ## $`Residual analysis`$`residual analysis` ## values ## p.value Shapiro-Wilk test 0.0847 ## p.value Bartlett test (factor_1) 0.0888 ## p.value Bartlett test (factor_2) 0.1543 ## p.value Bartlett test (treatments) 0.2051 ## coefficient of variation (%) 10.8100 ## first value most discrepant 59.0000 ## second value most discrepant 46.0000 ## third value most discrepant 25.0000 ## ## $`Residual analysis`$residuals ## 1 2 3 4 5 6 7 ## -1.0666667 0.2666667 3.7333333 -1.1666667 0.4166667 -2.9000000 0.6333333 ## 8 9 10 11 12 13 14 ## 2.9166667 -2.8333333 0.8853333 0.5186667 -1.0146667 3.3853333 -0.8313333 ## 15 16 17 18 19 20 21 ## 2.2520000 -1.8146667 -1.6680000 1.6686667 -3.3813333 2.6053333 -2.2613333 ## 22 23 24 25 26 27 28 ## -0.7946667 -2.0946667 0.4886667 6.5720000 -2.8946667 1.7520000 -3.7113333 ## 29 30 31 32 33 34 35 ## 0.3386667 -1.1746667 2.6586667 -0.8746667 -4.9746667 0.1086667 0.1920000 ## 36 37 38 39 40 41 42 ## 0.9253333 1.4720000 1.1086667 0.5586667 -1.0546667 1.1786667 -2.6546667 ## 43 44 45 46 47 48 49 ## 2.8453333 1.0286667 0.2120000 7.2453333 -1.0080000 -4.0713333 -3.7213333 ## 50 51 52 53 54 55 56 ## -0.1946667 -2.3613333 1.6053333 2.0053333 -1.2113333 -6.3280000 -4.0946667 ## 57 58 59 ## -0.5480000 2.0886667 9.0386667 ## ## $`Residual analysis`$`standardized residuals` ## 1 2 3 4 5 6 ## -0.37654793 0.09413698 1.31791775 -0.41184930 0.14708903 -1.02373968 ## 7 8 9 10 11 12 ## 0.22357533 1.02962324 -1.00020543 0.31253478 0.18309643 -0.35819122 ## 13 14 15 16 17 18 ## 1.19506899 -0.29347204 0.79498681 -0.64060216 -0.58882682 0.58906216 ## 19 20 21 22 23 24 ## -1.19365693 0.91971831 -0.79828161 -0.28052821 -0.73944599 0.17250602 ## 25 26 27 28 29 30 ## 2.32000592 -1.02185694 0.61847997 -1.31015145 0.11955397 -0.41467341 ## 31 32 33 34 35 36 ## 0.93854571 -0.30876930 -1.75612540 0.03836082 0.06777863 0.32665533 ## 37 38 39 40 41 42 ## 0.51963614 0.39137450 0.19721698 -0.37231176 0.41608546 -0.93713365 ## 43 44 45 46 47 48 ## 1.00444160 0.36313341 0.07483890 2.55770180 -0.35583779 -1.43723637 ## 49 50 51 52 53 54 ## -1.31368158 -0.06872000 -0.83358297 0.56670463 0.70791010 -0.42761724 ## 55 56 57 58 59 ## -2.23387058 -1.44547336 -0.19345150 0.73732791 3.19077300 O quadro geral da ANOVA indica que os dois fatores, bem como a interação são significativos: r.aov[1] ## $`Analysis of variance` ## df type III SS mean square F value p&gt;F ## factor_1 2 113.1605 56.5803 5.349 0.0083 ## factor_2 1 1890.1081 1890.1081 178.6876 &lt;0.001 ## blocks 9 91.7117 10.1902 0.9634 0.4825 ## factor_1:factor_2 2 132.6536 66.3268 6.2704 0.004 ## residuals 44 465.4199 10.5777 - - Parte-se direto, portanto, para a análise dos respectivos desdobramentos presentes nas posições 6 e 8 da lista de resultados (r.aov[6] e r.aov[8]): # Comparação de médias do fator 1 dentro do fator 2 r.aov[6] ## $`Adjusted means (factor 1 in levels of factor 2)` ## $`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in 2` ## treatment adjusted.mean standard.error tukey snk duncan t scott_knott ## 1 0.2 27.800 1.0285 a a a a a ## 3 100.2 23.072 1.0285 b b b b b ## 2 50.2 22.020 1.0285 b b b b b ## ## $`Adjusted means (factor 1 in levels of factor 2)`$`factor_1 in 5` ## treatment adjusted.mean standard.error tukey snk duncan t scott_knott ## 6 100.5 37.58 1.0285 a a a a a ## 4 0.5 35.10 1.0285 a a ab ab a ## 5 50.5 34.26 1.0285 a a b b a # Comparação de médias do fator 2 dentro do fator 1 r.aov[8] ## $`Adjusted means (factor 2 in levels of factor 1)` ## $`Adjusted means (factor 2 in levels of factor 1)`$`factor_2 in 0` ## treatment adjusted.mean standard.error tukey snk duncan t scott_knott ## 4 0.5 35.1 1.0285 a a a a a ## 1 0.2 27.8 1.0285 b b b b b ## ## $`Adjusted means (factor 2 in levels of factor 1)`$`factor_2 in 50` ## treatment adjusted.mean standard.error tukey snk duncan t scott_knott ## 5 50.5 34.26 1.0285 a a a a a ## 2 50.2 22.02 1.0285 b b b b b ## ## $`Adjusted means (factor 2 in levels of factor 1)`$`factor_2 in 100` ## treatment adjusted.mean standard.error tukey snk duncan t scott_knott ## 6 100.5 37.580 1.0285 a a a a a ## 3 100.2 23.072 1.0285 b b b b b Fique atento! O pacote easyanova não diferencia fatores qualitativos e quantitativos, analisando todos os fatores e seus desdobramentos com teste comparativo de média. "],["parcela-subdividida.html", "Cap. 10 Parcela subdividida 10.1 O caso balanceado 10.2 O caso desbalanceado", " Cap. 10 Parcela subdividida No delineamento em parcelas subdivididas existem dois tipos de tratamento: o principal e o secundário. As parcelas são subdivididas no espaço, ou no tempo. Depois que os tratamentos principais são sorteados nas parcelas, sorteia-se o tratamento secundário nas subparcelas de cada parcela. Indica-se o uso de parcelas subdivididas quando: A parcela é uma unidade que pode receber vários tratamentos secundários. No setor florestal esta unidade pode ser uma vaso, ou mesmo uma árvore. Não é possível instalar o experimento no esquema fatorial. O tratamento principal exige parcelas custosas, seja do ponto de vista financeiro ou do esforço. A busca pela precisão está no tratamento secundário. Deseja-se que a Variação entre subparcelas seja menor que entre as parcelas. O modelo estatístico do delineamento fatorial duplo inteiramente casualizado é: \\[Y = Xmed + BLOCO + TRAT A + Erro Parcela + TRAT B + (TRAT A * TRAT B) + Erro Subparcela\\] 10.1 O caso balanceado Como exemplo de um desenho de parcela subdividida balanceado, vamos analisar um experimento de regeneração natural do sub bosque de três formações florestais. Nas parcelas de cada uma das área naturais estudadas, implantaram-se subparcelas correspondendo a três alturas de desrama. O efeito dos tratamentos foi medido através do número de indivíduos regenerantes. Fator na parcela: Floresta A, B e C Fator nas subparcelas: Desrama 2, 5 e 7 metros 3 repetições Variável de interesse: número de indivíduos regenerantes Table 10.1: Dados de experimento em parcela subdividida floresta rep desrama indiv A 1 2 48 A 2 2 47 A 3 2 47 A 1 5 79 A 2 5 62 A 3 5 65 A 1 7 101 A 2 7 105 A 3 7 112 B 1 2 90 B 2 2 97 B 3 2 114 B 1 5 123 B 2 5 145 B 3 5 122 B 1 7 172 B 2 7 157 B 3 7 177 C 1 2 100 C 2 2 101 C 3 2 103 C 1 5 130 C 2 5 133 C 3 5 140 C 1 7 144 C 2 7 147 C 3 7 148 O primeiro passo é importar o arquivo csv contendo os resultados do experimento para dentro do R. Esta tarefa pode ser realizada através do seguinte comando: sub = read.csv(&quot;./data/Experimento Subdividida.csv&quot;, sep = &quot;,&quot;, dec = &quot;.&quot;) Você já sabe! Antes de ir para análise estatística explore graficamente seus dados. Veja alguns exemplos de gráficos que podem ajudá-lo a construir suas hipóteses e antecipar os resultados que serão apresentados pelas análise estatística: # Considerando apenas tratamento principal boxplot(data = sub, indiv ~ floresta) # Considerando apenas tratamento secundário plot(data = sub, indiv ~ desrama) # Interação dos tratamentos boxplot(data = sub, indiv ~ floresta/desrama) # Isolando os níveis de desrana # Fixando desrana até 2 metros boxplot(data = sub[sub$desrama == 2,], indiv ~ floresta) # Fixando desrana até 5 metros boxplot(data = sub[sub$desrama == 5,], indiv ~ floresta) # Fixando desrana até 7 metros boxplot(data = sub[sub$desrama == 7,], indiv ~ floresta) # Isolando os tipos de floresta # Fixando floresta igual a A plot(data = sub[sub$floresta == &quot;A&quot;,], indiv ~ desrama) # Fixando floresta igual a B plot(data = sub[sub$floresta == &quot;B&quot;,], indiv ~ desrama) # Fixando floresta igual a C plot(data = sub[sub$floresta == &quot;C&quot;,], indiv ~ desrama) Analisando os gráficos acima, os fatores parecem significativos, assim como a interação. Os dados apresentam-se consistentes, sem a presença pontos fora da tendência. Infelizmente o pacote ExpDes.pt não inclui as análises de pressuposição para o delineamento de parcelas subdivididas. Existem várias maneiras de contornar esta questão, uma delas é combinar as qualidades de diferentes pacotes. Aqui por exemplo, podemos rodar a ANOVA a partir de ambos os pacotes easyanova e ExpDes.pt. Assim podemos utilizar os testes estatísticos das pressuposições de um e a ANOVA e desdobramentos do outro. require(easyanova) r.aov = ea2(sub, design=4) Para conferência, é possível verificar que a ANOVA é igual em ambos os pacotes. r.aov[1] ## $`Marginal anova (Type III Sum of Squares)` ## numDF denDF F-value p-value ## plot 2 6 267.37381 &lt;.0001 ## split.plot 2 12 94.56819 &lt;.0001 ## plot:split.plot 4 12 2.55256 0.0935 Como já vimos anteriormente, o teste de normalidade e de homogeneidade de variâncias pode ser obtida através da posição 10 da lista de resultados da função easyanova. r.aov[10] ## $`Residual analysis` ## $`Residual analysis`$values ## values ## p.value Shapiro-Wilk test 0.4583 ## p.value Bartlett test (plot) 0.0036 ## p.value Bartlett test (split.plot) 0.5945 ## p.value Bartlett test (plot*split.plot) 0.0264 ## AIC 171.9126 ## BIC 182.5971 ## first value most discrepant 14.0000 ## second value most discrepant 12.0000 ## third value most discrepant 17.0000 ## Mean Square of Error a 35.6667 ## Mean Square of Error b 64.0009 ## Coefficient of Variation a 5.3589 ## Coefficient of Variation b 7.1785 ## ## $`Residual analysis`$residuals ## 1 2 3 4 5 6 ## 0.6605916 -0.3252332 -0.3353584 10.3272582 -6.6585666 -3.6686917 ## 7 8 9 10 11 12 ## -5.0060751 -0.9918999 5.9979750 -10.3191581 -3.3333333 13.6524915 ## 13 14 15 16 17 18 ## -6.9858248 15.0000000 -8.0141752 3.3475085 -11.6666667 8.3191581 ## 19 20 21 22 23 24 ## -1.3252332 -0.3323208 1.6575540 -4.3252332 -1.3323208 5.6575540 ## 25 26 27 ## -2.3252332 0.6676792 1.6575540 ## attr(,&quot;label&quot;) ## [1] &quot;Residuals&quot; ## ## $`Residual analysis`$`standardized residuals` ## 1 2 3 4 5 6 ## 0.09926874 -0.04887361 -0.05039514 1.55190283 -1.00059939 -0.55130344 ## 7 8 9 10 11 12 ## -0.75227538 -0.14905527 0.90133065 -1.55068561 -0.50090831 2.05159391 ## 13 14 15 16 17 18 ## -1.04977730 2.25408738 -1.20431008 0.50303845 -1.75317907 1.25014062 ## 19 20 21 22 23 24 ## -0.19914610 -0.04993868 0.24908478 -0.64996357 -0.20021117 0.85017474 ## 25 26 27 ## -0.34941859 0.10033381 0.24908478 A sintaxe da função para análise de parcela subdividida no pacote ExpDes.pt é: psub2.dic(fator1, fator2, repet, resp, quali = c(TRUE, TRUE), mcomp = &quot;tukey&quot;, fac.names = c(&quot;F1&quot;, &quot;F2&quot;), sigT = 0.05, sigF = 0.05) No nosso exemplo temos o fator principal (fator 1) como qualitativo e o fator secundário (fator 2) como quantitativo. Assim informando os parâmetros obrigatórios juntamente com os parâmetros quali e fac.names (nomes dos fatores) temos: require(ExpDes.pt) psub2.dic(sub$floresta, sub$desrama, sub$rep, sub$indiv, quali = c(TRUE, FALSE), fac.names = c(&quot;Floresta&quot;, &quot;Desrama&quot;)) ## ------------------------------------------------------------------------ ## Legenda: ## FATOR 1 (parcela): Floresta ## FATOR 2 (subparcela): Desrama ## ------------------------------------------------------------------------ ## ## ------------------------------------------------------------------------ ## $`Quadro da analise de variancia` ## GL SQ QM Fc Pr(&gt;Fc) ## Floresta 2 19073 6 3 4 ## Erro a 6 214 3 1 1 ## Desrama 2 14795 4 4 2 ## Floresta*Desrama 4 799 2 2 3 ## Erro b 12 939 5 ## Total 26 35819 1 1 1 ## ## ------------------------------------------------------------------------ ## CV 1 = 5.358865 % ## CV 2 = 7.936091 % ## ## ------------------------------------------------------------------------ ## #Teste de normalidade dos residuos (Shapiro-Wilk) ## valor-p: 0.5769146 ## De acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais. ## ------------------------------------------------------------------------ ## ## Interacao nao significativa: analisando os efeitos simples ## ------------------------------------------------------------------------ ## Floresta ## Teste de Tukey ## ------------------------------------------------------------------------ ## Grupos Tratamentos Medias ## a B 133 ## a C 127.3333 ## b A 74 ## ------------------------------------------------------------------------ ## ## Desrama ## Ajuste de modelos polinomiais de regressao ## ------------------------------------------------------------------------ ## ## Modelo Linear ## ========================================= ## Estimativa Erro.padrao tc valor.p ## ----------------------------------------- ## b0 58.7193 4.2238 13.9021 0 ## b1 11.2982 0.8284 13.6395 0 ## ----------------------------------------- ## ## R2 do modelo linear ## -------- ## 0.983607 ## -------- ## ## Analise de variancia do modelo linear ## ============================================================== ## GL SQ QM Fc valor.p ## -------------------------------------------------------------- ## Efeito linear 1 14,552.1400 14,552.1400 186.04 0 ## Desvios de Regressao 1 242.5263 242.5263 3.1 0.10371 ## Residuos 12 938.6667 78.2222 ## -------------------------------------------------------------- ## ------------------------------------------------------------------------ ## ## Modelo quadratico ## ======================================== ## Estimativa Erro.padrao tc valor.p ## ---------------------------------------- ## b0 75 10.1652 7.3781 0.00001 ## b1 1.8667 5.4200 0.3444 0.7365 ## b2 1.0667 0.6058 1.7608 0.1037 ## ---------------------------------------- ## ## R2 do modelo quadratico ## - ## 1 ## - ## ## Analise de variancia do modelo quadratico ## ============================================================== ## GL SQ QM Fc valor.p ## -------------------------------------------------------------- ## Efeito linear 1 14,552.1400 14,552.1400 186.04 0 ## Efeito quadratico 1 242.5263 242.5263 3.1 0.10371 ## Desvios de Regressao 0 0 0 0 1 ## Residuos 12 938.6667 78.2222 ## -------------------------------------------------------------- ## ------------------------------------------------------------------------ Como esperado significância dos fatores: floresta e desrama. No entanto, a interação não foi significativa a 5%. Desta forma, não é necessário analisar a interação entre os fatores. 10.2 O caso desbalanceado Neste exemplo desbalanceado vamos analisar um experimento em que três alturas de desrama são subdivididos em três espécies florestais. O efeito dos tratamentos foi medido através da produção de madeira em metros cúbicos. Fator na parcela: Espécie florestal: A, B ou C. Fator nas subparcelas: Desrama 2, 5 e 7 metros. 3 repetições. Observações perdidas: Espécie A, desrama 2 metros e repetição 2. Espécie C, desrama 2 metros e repetição 2. Espécie C, desrama 5 metros e repetição 1. Espécie C, desrama 7 metros e repetição 1. Variável de interesse: número de indivíduos regenerantes. Table 10.2: Dados de outro experimento em parcela subdividida, porém desbalanceado. especie rep desrama volume A 1 2 48 A 3 2 47 A 1 5 79 A 2 5 62 A 3 5 65 A 1 7 131 A 2 7 65 A 3 7 112 B 1 2 80 B 2 2 97 B 3 2 114 B 1 5 123 B 2 5 145 B 3 5 122 B 1 7 172 B 2 7 157 B 3 7 177 C 1 2 100 C 3 2 103 C 2 5 133 C 3 5 104 C 2 7 147 C 3 7 119 O primeiro passo é importar o arquivo csv contendo os resultados do experimento para dentro do R. Esta tarefa pode ser realizada através do seguinte comando: sub2 = read.csv(&quot;./data/Experimento Subdividida 2.csv&quot;, sep = &quot;,&quot;, dec = &quot;.&quot;) Os dados devem ser explorados graficamente antes de seguir com a análise de variância do experimento. Veja os gráficos abaixo e tente antecipar os resultados dos testes estatísticos. # Considerando apenas tratamento principal boxplot(data = sub2, volume ~ especie) # Considerando apenas tratamento secundário plot(data = sub2, volume ~ desrama) # Interação dos tratamentos boxplot(data = sub2, volume ~ especie/desrama) # Isolando os níveis de desrama # Fixando desrana até 2 metros boxplot(data = sub2[sub2$desrama == 2,], volume ~ especie) # Fixando desrama até 5 metros boxplot(data = sub2[sub2$desrama == 5,], volume ~ especie) # Fixando desrama até 7 metros boxplot(data = sub2[sub2$desrama == 7,], volume ~ especie) # Isolando os tipos de floresta # Fixando espécie igual a A plot(data = sub2[sub2$especie == &quot;A&quot;,], volume ~ desrama) # Fixando espécie igual a B plot(data = sub2[sub2$especie == &quot;B&quot;,], volume ~ desrama) # Fixando espécie igual a C plot(data = sub2[sub2$especie == &quot;C&quot;,], volume ~ desrama) Os dados por se tratarem de experimento desbalanceados com efeito da interação relevante devem ser analisados com o pacote easyanova. A função será ea2() e possui a sintaxe básica: ea2(data, design = 1, alpha = 0.05, cov = 4, list = FALSE, p.adjust=1, plot=2) Os dados devem ser apresentados na ordem: Fator nas parcelas Repetição Fator nas subparcelas Variável resposta O parâmetro design deve ser ajustado para 4, resultando no seguinte comando: require(easyanova) r.aov = ea2(sub2, design=4) Os resultados podem ser acessados escolhendo qual elemento da lista deseja ser visualizado: r.aov[10] ## $`Residual analysis` ## $`Residual analysis`$values ## values ## p.value Shapiro-Wilk test 0.8313 ## p.value Bartlett test (plot) 0.4160 ## p.value Bartlett test (split.plot) 0.2427 ## p.value Bartlett test (plot*split.plot) 0.6827 ## AIC 165.0415 ## BIC 172.7102 ## first value most discrepant 7.0000 ## second value most discrepant 6.0000 ## third value most discrepant 13.0000 ## Mean Square of Error a 402.7662 ## Mean Square of Error b 220.3501 ## Coefficient of Variation a 18.4488 ## Coefficient of Variation b 13.6457 ## ## $`Residual analysis`$residuals ## 1 2 3 4 5 6 ## -2.8241221 2.8241221 1.6212788 4.1091983 -5.7304770 19.6212788 ## 7 8 9 10 11 12 ## -26.8908017 7.2695230 -12.9589104 -0.6517886 13.6106990 -2.9589104 ## 13 14 15 16 17 18 ## 14.3482114 -11.3893010 7.3744229 -12.3184553 4.9440324 -3.5066019 ## 19 20 21 22 23 ## 3.5066019 7.9988237 -7.9988237 7.4988237 -7.4988237 ## attr(,&quot;label&quot;) ## [1] &quot;Residuals&quot; ## ## $`Residual analysis`$`standardized residuals` ## 1 2 3 4 5 6 ## -0.26911379 0.26911379 0.15449349 0.39157015 -0.54606364 1.86973386 ## 7 8 9 10 11 12 ## -2.56245492 0.69272107 -1.23486923 -0.06210968 1.29697891 -0.28195792 ## 13 14 15 16 17 18 ## 1.36725729 -1.08529938 0.70271711 -1.17383954 0.47112244 -0.33414806 ## 19 20 21 22 23 ## 0.33414806 0.76221696 -0.76221696 0.71457139 -0.71457139 O teste de normalidade apresentou valor não significativo, indicando assim que não há evidências para rejeitar a normalidade dos resíduos. r.aov[1] ## $`Marginal anova (Type III Sum of Squares)` ## numDF denDF F-value p-value ## plot 2 6 16.07861 0.0039 ## split.plot 2 8 21.60633 0.0006 ## plot:split.plot 4 8 1.27547 0.3555 Sendo a interação não significativa, os fatores (da parcela e da subparcela) devem ser analisados independentemente. # Comparação das parcelas r.aov[2] ## $`Adjusted means (plot)` ## plot adjusted.mean standard.error tukey snk duncan t ## 1 B 131.8889 7.6958 a a a a ## 2 C 118.3355 8.6638 a a a a ## 3 A 71.1485 8.0186 b b b b # Comparação das subdivisões r.aov[4] ## $`Adjusted means (split.plot)` ## split.plot adjusted.mean standard.error tukey snk duncan t ## 1 7 134.5013 6.4491 a a a a ## 2 5 105.4458 6.4491 b b b b ## 3 2 81.4258 6.8129 c c c c "],["análise-experimental-não-paramétrica.html", "Cap. 11 Análise experimental não paramétrica 11.1 Kruskal-Wallis (equivalente ao DIC) 11.2 Friedman (equivalente ao DBC)", " Cap. 11 Análise experimental não paramétrica Os testes estatísticos não paramétricos não levam em consideração a distribuição original dos resíduos. Em geral eles seguem o mesmo procedimento que os testes paramétricos. Iniciando pela formulação da hipótese, em seguida computa-se o valor da estatística do teste com base nos dados obtidos de amostras aleatórias e compara-se a grandeza estatística do valor calculado com a referência. Aceitando ou rejeitando a hipótese nula. Assim como os teste paramétricos, existem inúmeros testes indicados para as diferentes hipóteses a serem testadas. ## Warning in read.table(file = file, header = header, sep = sep, quote = quote, : ## incomplete final line found by readTableHeader on &#39;./data/naoParam.csv&#39; Table 11.1: Testes não paramétricos e referência para utilização Tipo Numero.de.variaveis Parametrico Nao.parametrico Dependente 2 Teste t Mann-Whitney Independente 2 Teste t Wilcoxon Independente &gt; 2 ANOVA DIC Kruskal-Wallis Independente &gt; 2 ANOVA DBC Friedman Aqui mostraremos um exemplo de análise não paramétrica de um experimento inteiramente casualizado (DIC) e outro em blocos casualizados (DBC). 11.1 Kruskal-Wallis (equivalente ao DIC) Neste exemplo, iremos analisar um experimento que avalia o crescimento em altura das árvores remanescente em de três intensidades de desbaste. Table 11.2: Experimento em delineamento inteiramente casualizado. desbaste rep dap 30 1 0.62 30 2 0.62 30 3 0.62 30 4 0.11 30 5 0.21 30 6 0.11 30 7 0.62 30 8 0.62 30 9 0.12 30 10 0.62 40 1 0.33 40 2 0.34 40 3 0.86 40 4 0.81 40 5 0.86 40 6 0.88 40 7 0.10 40 8 0.14 40 9 0.12 40 10 0.83 60 1 1.11 60 2 0.24 60 3 1.11 60 4 0.24 60 5 0.25 60 6 1.11 60 7 1.02 60 8 1.09 60 9 1.11 60 10 1.11 O primeiro passo é importar o arquivo csv contendo os resultados do experimento para dentro do R. Esta tarefa pode ser realizada através do seguinte comando: dic.np = read.csv(&quot;./data/Experimento DIC NP.csv&quot;) O primeiro passo é importar os dados e criar os gráficos auxiliares: plot(data = dic.np, dap ~ desbaste) Os dados indicam que o incremento médio das árvores remanescentes de um desbaste de 60% da área basal cresceram aproximadamente 0.8 cm, ao passo que as árvores remanescentes de um desbaste de 40 % e 30 %, cresceram apenas ~ 0.6 e 0.5 cm respectivamente. Espera-se que o desbaste 60% seja significativamente diferente dos demais. require(ExpDes.pt) dic(dic.np$desbaste, dic.np$dap, quali = FALSE) ## ------------------------------------------------------------------------ ## Quadro da analise de variancia ## ------------------------------------------------------------------------ ## GL SQ QM Fc Pr&gt;Fc ## Tratamento 2 0.9236 3 3.9172 0.032084 ## Residuo 27 3.1831 2 ## Total 29 4.1067 1 ## ------------------------------------------------------------------------ ## CV = 57.45 % ## ## ------------------------------------------------------------------------ ## Teste de normalidade dos residuos ## Valor-p: 0.0001554767 ## ATENCAO: a 5% de significancia, os residuos nao podem ser considerados normais! ## ------------------------------------------------------------------------ ## ## ------------------------------------------------------------------------ ## Teste de homogeneidade de variancia ## valor-p: 0.3609866 ## De acordo com o teste de bartlett a 5% de significancia, as variancias podem ser consideradas homogeneas. ## ------------------------------------------------------------------------ ## ## Ajuste de modelos polinomiais de regressao ## ------------------------------------------------------------------------ ## ## Modelo Linear ## ========================================= ## Estimativa Erro.padrao tc valor.p ## ----------------------------------------- ## b0 -0.0090 0.2266 -0.0397 0.9686 ## b1 0.0140 0.0050 2.7854 0.0097 ## ----------------------------------------- ## ## R2 do modelo linear ## -------- ## 0.990299 ## -------- ## ## Analise de variancia do modelo linear ## ================================================== ## GL SQ QM Fc valor.p ## -------------------------------------------------- ## Efeito linear 1 0.9147 0.9147 7.76 0.00966 ## Desvios de Regressao 1 0.0090 0.0090 0.08 0.78489 ## Residuos 27 3.1831 0.1179 ## -------------------------------------------------- ## ------------------------------------------------------------------------ ## ## Modelo quadratico ## ========================================= ## Estimativa Erro.padrao tc valor.p ## ----------------------------------------- ## b0 0.3510 1.3254 0.2648 0.7932 ## b1 -0.0031 0.0621 -0.0494 0.9610 ## b2 0.0002 0.0007 0.2757 0.7849 ## ----------------------------------------- ## ## R2 do modelo quadratico ## - ## 1 ## - ## ## Analise de variancia do modelo quadratico ## ================================================== ## GL SQ QM Fc valor.p ## -------------------------------------------------- ## Efeito linear 1 0.9147 0.9147 7.76 0.00966 ## Efeito quadratico 1 0.0090 0.0090 0.08 0.78489 ## Desvios de Regressao 0 0 0 0 1 ## Residuos 27 3.1831 0.1179 ## -------------------------------------------------- ## ------------------------------------------------------------------------ O teste de normalidade de resíduos é significativo, indicando que o modelo estatístico escolhido não é adequado aos dados, e mesmo transformando os dados, a normalidade de resíduos continua sendo rejeitada. Neste caso, recomenda-se o uso do teste não paramétrico de Kruskal-Wallis. kruskal.test(dic.np$dap, dic.np$desbaste) ## ## Kruskal-Wallis rank sum test ## ## data: dic.np$dap and dic.np$desbaste ## Kruskal-Wallis chi-squared = 7.8861, df = 2, p-value = 0.01939 O teste indica que o tratamento é significativo, e portanto, as médias dos desbaste não podem ser consideradas iguais. Como foi antecipado pelo gráfico, pelo menos um nível de desbaste se difere dos demais. Não há desdobramento específico para os teste não paramétricos, sendo a interpretação gráfica e a estatística descritiva o caminho ideal para avaliar desdobramento. 11.2 Friedman (equivalente ao DBC) Neste exemplo, iremos analisar um experimento que avalia o crescimento em diâmetro das árvores remanescente após duas intensidades de desbaste. O delineamento foi construído considerando blocos. Table 11.3: Experimento em delineamento em blocos casualizados. desbaste bloco rep diametro 30 1 1 29.700 30 1 2 34.980 30 1 3 24.420 30 1 4 28.380 30 2 1 25.740 30 2 2 23.100 30 2 3 27.060 30 2 4 15.180 30 3 1 30.360 30 3 2 27.060 30 3 3 33.660 30 3 4 22.440 30 4 1 32.340 30 4 2 29.040 30 4 3 14.520 30 4 4 31.680 30 5 1 32.340 30 5 2 19.140 30 5 3 32.340 30 5 4 31.680 50 1 1 33.660 50 1 2 33.660 50 1 3 33.660 50 1 4 30.360 50 2 1 31.020 50 2 2 31.680 50 2 3 28.380 50 2 4 31.416 50 3 1 26.400 50 3 2 32.340 50 3 3 33.000 50 3 4 31.680 50 4 1 34.980 50 4 2 31.680 50 4 3 33.000 50 4 4 23.100 50 5 1 28.380 50 5 2 32.340 50 5 3 32.340 50 5 4 22.440 O primeiro passo é importar o arquivo csv contendo os resultados do experimento para dentro do R. Esta tarefa pode ser realizada através do seguinte comando: dbc.np = read.csv(&quot;./data/Experimento DBC 3.csv&quot;) É fundamental explorar os dados de forma gráfica para conhecer melhor os dados e antecipar o resultado da análise estatística. A construção do gráfico ajuda na compreensão do fenômeno estudado e na validação da análise estatística escolhida. Por se tratar de um experimento com o tratamento formado por níveis qualitativos, recomenda-se o uso do boxplot. boxplot(data = dbc.np, diametro ~ desbaste) plot(data = dbc.np, diametro ~ bloco) A análise do experimento em questão pode ser então realizado construindo a função dbc() da seguinte maneira: require(ExpDes.pt) dbc(dbc.np$desbaste, dbc.np$bloco, dbc.np$diametro, hvar = &#39;han&#39;) ## ------------------------------------------------------------------------ ## Quadro da analise de variancia ## ------------------------------------------------------------------------ ## GL SQ QM Fc Pr&gt;Fc ## Tratamento 1 123.75 2 5.2404 0.02840 ## Bloco 4 81.30 3 0.8607 0.49731 ## Residuo 34 802.89 4 ## Total 39 1007.94 1 ## ------------------------------------------------------------------------ ## CV = 16.75 % ## ## ------------------------------------------------------------------------ ## Teste de normalidade dos residuos ## valor-p: 0.002575723 ## ATENCAO: a 5% de significancia, os residuos nao podem ser considerados normais! ## ------------------------------------------------------------------------ ## ## ------------------------------------------------------------------------ ## Teste de homogeneidade de variancia ## valor-p: 0.1026776 ## De acordo com o teste de han a 5% de significancia, as variancias podem ser consideradas homogeneas. ## ------------------------------------------------------------------------ ## ## Teste de Tukey ## ------------------------------------------------------------------------ ## Grupos Tratamentos Medias ## a 50 30.7758 ## b 30 27.258 ## ------------------------------------------------------------------------ Veja que o teste de normalidade deu significativo, indicando assim que a hipótese de normalidade de resíduos deve ser rejeitada. A variável diametro é contínua e portanto a transformação logarítmica é a mais indicada para a transformação dos dados. dbc(dbc.np$desbaste, dbc.np$bloco, log(dbc.np$diametro), hvar = &#39;han&#39;) ## ------------------------------------------------------------------------ ## Quadro da analise de variancia ## ------------------------------------------------------------------------ ## GL SQ QM Fc Pr&gt;Fc ## Tratamento 1 0.20102 4 5.0766 0.03081 ## Bloco 4 0.12703 2 0.8020 0.53242 ## Residuo 34 1.34633 3 ## Total 39 1.67439 1 ## ------------------------------------------------------------------------ ## CV = 5.94 % ## ## ------------------------------------------------------------------------ ## Teste de normalidade dos residuos ## valor-p: 0.0003432296 ## ATENCAO: a 5% de significancia, os residuos nao podem ser considerados normais! ## ------------------------------------------------------------------------ ## ## ------------------------------------------------------------------------ ## Teste de homogeneidade de variancia ## valor-p: 0.06966806 ## De acordo com o teste de han a 5% de significancia, as variancias podem ser consideradas homogeneas. ## ------------------------------------------------------------------------ ## ## Teste de Tukey ## ------------------------------------------------------------------------ ## Grupos Tratamentos Medias ## a 50 3.420159 ## b 30 3.278376 ## ------------------------------------------------------------------------ Infelizmente, mesmo com a transformação os resíduos continuam não apresentando normalidade. A recomendação portanto é seguir com a análise não paramétrica. Por se tratar de um DBC, o teste indicado é o Teste de Friedman. O teste de Friedman não aceita repetições dentro do bloco. Por isso, será necessário agregar as repetições através de média. dbc.aggr = aggregate(dbc.np$diametro, by = list(desb = dbc.np$desbaste, bloco = dbc.np$bloco), FUN = mean) print(dbc.aggr) ## desb bloco x ## 1 30 1 29.370 ## 2 50 1 32.835 ## 3 30 2 22.770 ## 4 50 2 30.624 ## 5 30 3 28.380 ## 6 50 3 30.855 ## 7 30 4 26.895 ## 8 50 4 30.690 ## 9 30 5 28.875 ## 10 50 5 28.875 O teste de Friedman pode ser assim chamado: friedman.test(x ~ desb | bloco, data = dbc.aggr) ## ## Friedman rank sum test ## ## data: x and desb and bloco ## Friedman chi-squared = 4, df = 1, p-value = 0.0455 Segundo o teste de Friedman, existe uma diferença significativa entre os desbaste. Uma exploração gráfica dos dados, ou uma análise estatística descritiva podem auxiliar no desdobramento do tratamento. "],["proximos-passos.html", "Cap. 12 Proximos passos", " Cap. 12 Proximos passos "]]
